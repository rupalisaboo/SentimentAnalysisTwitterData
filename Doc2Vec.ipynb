{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Split the all_views, get one file(sentiment, tweet) for each view\n",
    "#Clean each view\n",
    "#Run this for each view.\n",
    "norm() {\n",
    "    fn=$1\n",
    "    if [ ! -f \"$fn\" ]\n",
    "    then\n",
    "        echo \"File: $fn not found\"\n",
    "        return 0\n",
    "    fi\n",
    "    #this function will convert text to lowercase and will disconnect punctuation and special symbols from words\n",
    "    function normalize_text {\n",
    "        awk '{print tolower($0);}' < $1 | sed -e 's/\\./ \\. /g' -e 's/<br \\/>/ /g' -e 's/\"/ \" /g' \\\n",
    "        -e 's/,/ , /g' -e 's/(/ ( /g' -e 's/)/ ) /g' -e 's/\\!/ \\! /g' -e 's/\\?/ \\? /g' \\\n",
    "        -e 's/\\;/ \\; /g' -e 's/\\:/ \\: /g' > $1-norm\n",
    "    }\n",
    "    export LC_ALL=C\n",
    "    normalize_text \"$fn\"\n",
    "    wc -l $fn\n",
    "    mv \"$fn\" \"$fn-norm\"\n",
    "}\n",
    "norm \"data/view1_clean\" #file name is\n",
    "norm \"data/view2_clean\"\n",
    "norm \"data/test_clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "tw_view_1 = 'data/view1_clean-norm'\n",
    "tw_view_2 = 'data/view2_clean-norm'\n",
    "tw_test = 'data/test_clean-norm'\n",
    "assert os.path.isfile(tw_view_1), tw_view_1 + \" unavailable\"\n",
    "assert os.path.isfile(tw_view_2), tw_view_2 + \" unavailable\"\n",
    "assert os.path.isfile(tw_test), tw_test + \" unavailable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stem_document(doc_sentence):\n",
    "    words = doc_sentence.split()\n",
    "    stemmed = ' '.join([stemmer.stem(word) for word in words])\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "#from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple, defaultdict as dd\n",
    "\n",
    "#sentiment = {'positive':1, 'negative':-1} #, 'neutral':2}\n",
    "sentiment_dict = {'4':1, '0':-1} #- new data 0,4\n",
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags split sentiment')\n",
    "stem = True\n",
    "\n",
    "alldocs = dd(list)  # will hold all docs in original order - dictionary, keys = [v1, v2]\n",
    "v1 = 'view1'\n",
    "v2 = 'view2'\n",
    "#tw_sentiment_dict = {}\n",
    "#print total_num, train_test_shuffle\n",
    "all_v2_words = []\n",
    "with open(tw_view_2) as allview2:\n",
    "        all_v2_words = allview2.readlines()\n",
    "total_num = len(all_v2_words)\n",
    "#split train/test\n",
    "train_num = total_num *  9 / 10 # 70% train/test 1 - 10\n",
    "train_test_shuffle = np.arange(total_num)\n",
    "np.random.shuffle(train_test_shuffle)\n",
    "with open(tw_view_1) as allview1:\n",
    "    #for line_no, (v1, v2) in enumerate(zip(allview1, allview2)):\n",
    "    for line_no, line in enumerate(allview1):\n",
    "        tokens = gensim.utils.to_unicode(line).split('\\t')\n",
    "        if len(tokens) != 2:\n",
    "            print line\n",
    "            raise Exception()\n",
    "        sentiment = sentiment_dict[tokens[0]]\n",
    "        #if tw_id not in tw_sentiment_dict.keys():\n",
    "        #    continue\n",
    "        words = tokens[1]\n",
    "        split = 'train' if train_test_shuffle[line_no] <= train_num else 'dev'\n",
    "        #sentiment = tw_sentiment_dict[tw_id]\n",
    "        v2_words = gensim.utils.to_unicode(all_v2_words[line_no]).split('\\t')[1]\n",
    "        \n",
    "        alldocs[v1].append(SentimentDocument(stem_document(words) if stem else words, \\\n",
    "                                             ['%d_%s' %(line_no, v1)], split, sentiment))\n",
    "        alldocs[v2].append(SentimentDocument(stem_document(v2_words) if stem else v2_words, \\\n",
    "                                             ['%d_%s' %(line_no, v2)], split, sentiment))\n",
    "# test file\n",
    "with open(tw_test) as test_fh:\n",
    "    for line_no, line in enumerate(test_fh):\n",
    "        tokens = gensim.utils.to_unicode(line).split('\\t')\n",
    "        if len(tokens) != 2:\n",
    "            print line\n",
    "            raise Exception()\n",
    "        sentiment = sentiment_dict[tokens[0]]\n",
    "        #if tw_id not in tw_sentiment_dict.keys():\n",
    "        #    continue\n",
    "        words = tokens[1]\n",
    "        split = 'test'\n",
    "        \n",
    "        alldocs[v1].append(SentimentDocument(stem_document(words) if stem else words, \\\n",
    "                                             ['%d_%s' %(total_num + line_no, v1)], split, sentiment))\n",
    "train_docs = {\n",
    "    v1 : [doc for doc in alldocs[v1] if doc.split == 'train'],\n",
    "    v2 : [doc for doc in alldocs[v2] if doc.split == 'train']\n",
    "}\n",
    "dev_docs = {\n",
    "    v1 : [doc for doc in alldocs[v1] if doc.split == 'dev'],\n",
    "    v2 : [doc for doc in alldocs[v2] if doc.split == 'dev']\n",
    "}\n",
    "test_docs = {\n",
    "    v1 : [doc for doc in alldocs[v1] if doc.split == 'test']\n",
    "}\n",
    "doc_list = alldocs[v1][:] + alldocs[v2][:]  # for reshuffling per pass\n",
    "\n",
    "print('%d total(view1 + view2) docs. view1: %d train, %d dev, %d test' % (len(doc_list), len(train_docs[v1]), len(dev_docs[v1]), len(test_docs[v1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"this will be painfully slow otherwise\"\n",
    "model_size = 500\n",
    "\n",
    "simple_models = [\n",
    "    # PV-DM w/concatenation - window=5 (both sides) approximates paper's 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, size=model_size, window=3, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DBOW \n",
    "    Doc2Vec(dm=0, size=model_size, negative=5, hs=0, min_count=5, workers=cores),\n",
    "    # PV-DM w/average\n",
    "    Doc2Vec(dm=1, dm_mean=1, size=model_size, window=3, negative=5, hs=0, min_count=2, workers=cores),\n",
    "]\n",
    "\n",
    "# speed setup by sharing results of 1st model's vocabulary scan\n",
    "simple_models[0].build_vocab(doc_list)  # PV-DM/concat requires one special NULL word so it serves as template\n",
    "print simple_models[0]\n",
    "for model in simple_models[1:]:\n",
    "    model.reset_from(simple_models[0])\n",
    "    print model\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[1], simple_models[2]])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[1], simple_models[0]])\n",
    "#print models_by_name['dbow+dmm'], models_by_name['dbow+dmc'] \n",
    "#del models_by_name['dbow+dmc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn import svm, metrics, neighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from random import sample\n",
    "\n",
    "# for timing\n",
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "import time \n",
    "import ipdb\n",
    "\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = default_timer()\n",
    "    elapser = lambda: default_timer() - start\n",
    "    yield lambda: elapser()\n",
    "    end = default_timer()\n",
    "    elapser = lambda: end-start\n",
    "    \n",
    "def logistic_predictor(train_targets, train_regressors):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train_regressors, train_targets)\n",
    "    return lr\n",
    "\n",
    "def svm_predictor(train_targets, train_regressors):\n",
    "    svc = svm.SVC(kernel='rbf', degree=5, gamma=1e-1)\n",
    "    svc.fit(train_regressors, train_targets)\n",
    "    return svc\n",
    "\n",
    "    \"\"\"expected = svm_y_test\n",
    "    predicted = svc.predict(svm_x_test)\n",
    "\n",
    "    #print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "    #      % (svc, metrics.classification_report(expected, predicted)))\n",
    "    #print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "    \"\"\"\n",
    "def rf_predictor(train_targets, train_regressors):\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "    rfc.fit(train_regressors, train_targets)\n",
    "    return rfc\n",
    "\n",
    "def error_rate_for_model(test_model, train_set, test_set, \\\n",
    "                         infer=False, infer_steps=3, infer_alpha=0.1, infer_subsample=0.1):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets, train_regressors = zip(*[(doc.sentiment, test_model.docvecs[doc.tags[0]]) for doc in train_set])\n",
    "    predictor = predictor_alg(train_targets, train_regressors)\n",
    "\n",
    "    test_data = test_set\n",
    "    if infer:\n",
    "        if infer_subsample < 1.0:\n",
    "            test_data = sample(test_data, int(infer_subsample * len(test_data)))\n",
    "        test_regressors = [test_model.infer_vector(doc.words, steps=infer_steps, \\\n",
    "                                                   alpha=infer_alpha) for doc in test_data]\n",
    "    else:\n",
    "        test_regressors = [test_model.docvecs[doc.tags[0]] for doc in test_data]\n",
    "    \n",
    "    # predict & evaluate\n",
    "    test_predictions = predictor.predict(test_regressors)\n",
    "    predicted = np.rint(test_predictions)\n",
    "    expected = [doc.sentiment for doc in test_data]\n",
    "    \"\"\"if not infer:\n",
    "        print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "              % (predictor, metrics.classification_report(expected, predicted)))\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\"\"\"\n",
    "    #ipdb.set_trace()\n",
    "    corrects = sum(expected == predicted)\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.linalg import eigh\n",
    "%matplotlib inline\n",
    "def center(data):\n",
    "    return data - np.mean(data, axis=0)\n",
    "\n",
    "def PLS(X, Y):\n",
    "    cross_cov = np.dot(center(X), center(Y).T)\n",
    "    eigval,eigvec=np.linalg.eig(cross_cov.dot(cross_cov.T))\n",
    "    return (eigval, eigvec)\n",
    "\n",
    "def kcca(X, Y, regX=0.1, regY=0.1, numCC=10, kernelcca=True, ktype=\"gaussian\"):\n",
    "    '''Set up and solve the eigenproblem for the data in kernel and specified reg\n",
    "    '''\n",
    "    cenX = center(X)\n",
    "    cenY = center(Y)\n",
    "    kernel1 = np.array([_make_kernel(X.T, ktype=ktype)])\n",
    "    kernel_x = (kernel1 + kernel1.T)/2\n",
    "    kernel2 = np.array([_make_kernel(Y.T, ktype=ktype)])\n",
    "    kernel_y = (kernel2 + kernel2.T)/2\n",
    "    r_Ix = regX * np.eye(kernel_x.shape[0])\n",
    "    r_Iy = regY * np.eye(kernel_y.shape[0])\n",
    "    A = reduce(np.dot, [ np.linalg.inv(kernel_x - r_Ix), kernel_y, np.linalg.inv(kernel_y - r_Iy), kernel_x])\n",
    "    eigval,eigvec=np.linalg.eig(A)\n",
    "    return (eigval, eigvec)\n",
    "\n",
    "def _listcorr(a):\n",
    "    '''Returns pairwise row correlations for all items in array as a list of matrices\n",
    "    '''\n",
    "    corrs = np.zeros((a[0].shape[1], len(a), len(a)))\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(a)):\n",
    "            if j > i:\n",
    "                corrs[:, i, j] = [np.nan_to_num(np.corrcoef(ai, aj)[0, 1]) for (ai, aj) in zip(a[i].T, a[j].T)]\n",
    "    return corrs\n",
    "\n",
    "\n",
    "def recon(data, comp, corronly=False, kernelcca=True):\n",
    "    nT = data[0].shape[0]\n",
    "    # Get canonical variates and CCs\n",
    "    if kernelcca:\n",
    "        ws = _listdot(data, comp)\n",
    "    else:\n",
    "        ws = comp\n",
    "    ccomp = _listdot([d.T for d in data], ws)\n",
    "    corrs = _listcorr(ccomp)\n",
    "    if corronly:\n",
    "        return corrs\n",
    "    else:\n",
    "        return corrs, ws, ccomp\n",
    "\n",
    "\n",
    "def _listdot(d1, d2): return [np.dot(x[0].T, x[1]) for x in zip(d1, d2)]\n",
    "\n",
    "\n",
    "def _make_kernel(d, normalize=True, ktype=\"linear\", sigma=1.0):\n",
    "    '''Makes a kernel for data d\n",
    "      If ktype is \"linear\", the kernel is a linear inner product\n",
    "      If ktype is \"gaussian\", the kernel is a Gaussian kernel with sigma = sigma\n",
    "    '''\n",
    "    if ktype == \"linear\":\n",
    "        d = np.nan_to_num(d)\n",
    "        cd = _demean(d)\n",
    "        kernel = np.dot(cd, cd.T)\n",
    "    elif ktype == \"gaussian\":\n",
    "        from scipy.spatial.distance import pdist, squareform\n",
    "        # this is an NxD matrix, where N is number of items and D its dimensionalites\n",
    "        pairwise_dists = squareform(pdist(d, 'euclidean'))\n",
    "        kernel = np.exp(-pairwise_dists ** 2 / sigma ** 2)\n",
    "    kernel = (kernel + kernel.T) / 2.\n",
    "    kernel = kernel / np.linalg.eigvalsh(kernel).max()\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def _demean(d): return d - d.mean(0)\n",
    "\n",
    "def CCA(X, Y, regX = 0, regY = 0):\n",
    "    cenX = center(X)\n",
    "    cenY = center(Y)\n",
    "    cross_cov = cenX.dot(cenY.T)\n",
    "    covX = cenX.dot(cenX.T)\n",
    "    covY = cenY.dot(cenY.T)\n",
    "    r_Ix = regX * np.eye(covX.shape[0])\n",
    "    r_Iy = regY * np.eye(covY.shape[0])\n",
    "    A = reduce(np.dot, [ np.linalg.inv(covX + r_Ix), cross_cov, np.linalg.inv(covY + r_Iy), cross_cov.T ])\n",
    "    eigval,eigvec=np.linalg.eig(A)\n",
    "    return (eigval, eigvec)\n",
    "\n",
    "def get_top_eigvec(eigval, eigvec, k):\n",
    "    idx=np.argsort(eigval)[-k:][::-1]\n",
    "    #eigval=eigval[idx]\n",
    "    return eigvec[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from collections import defaultdict\n",
    "best_error = dd(lambda: dd(lambda :(1.0, 0.0))) # { view: { model_name : (error_rate, alpha) } } ,to selectively-print only best errors achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor_alg = logistic_predictor\n",
    "from random import shuffle\n",
    "import datetime\n",
    "\n",
    "print 'Started.'\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 10)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "print(\"START %s\" % datetime.datetime.now())\n",
    "\n",
    "for epoch in range(passes):\n",
    "    shuffle(doc_list)  # shuffling gets best results\n",
    "\n",
    "    for name, train_model in models_by_name.items():\n",
    "        #print name\n",
    "        # train\n",
    "        duration = 'na'\n",
    "        train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "        with elapsed_timer() as elapsed:\n",
    "            train_model.train(doc_list)\n",
    "            duration = '%.1f' % elapsed()\n",
    "\n",
    "        #print np.array(train_model.docvecs[['%d_%s' %(0, view)]]).shape\n",
    "        # evaluate\n",
    "        #view1, view2\n",
    "        for view in [v1, v2]:\n",
    "            eval_duration = ''\n",
    "            with elapsed_timer() as eval_elapsed:\n",
    "                err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs[view], dev_docs[view])\n",
    "            eval_duration = '%.1f' % eval_elapsed()\n",
    "            best_indicator = ' '\n",
    "            if err < best_error[view][name][0]:\n",
    "                best_error[view][name] = (err, alpha)\n",
    "                best_indicator = '*' \n",
    "            #print(\"%s%f : %i passes : %s-%s %ss %ss\" % (best_indicator, err, epoch + 1, view, name, duration, eval_duration))\n",
    "\n",
    "    #print('completed pass %i at alpha %f' % (epoch + 1, alpha))\n",
    "    alpha -= alpha_delta\n",
    "\n",
    "print(\"END %s\" % str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for view in [v1, v2]:\n",
    "    print '========= %s ========' %view\n",
    "    for rate, alpha, name in sorted((rate, alpha, name) for name, (rate, alpha) in best_error[view].items()):\n",
    "        print(\"%f %s %f\" % (rate, name, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_id = np.random.randint(len(train_docs[v2]) + len(dev_docs[v2]))  # pick random doc; re-run cell for more examples\n",
    "print('for doc %d...' % doc_id)\n",
    "# Print example tweet and vector reps for both views\n",
    "print alldocs[v1][doc_id]\n",
    "#tag = alldocs['view1'][doc_id].tags[0]\n",
    "#print '\\n', simple_models['view1'][0].docvecs[tag]\n",
    "\n",
    "print '\\n', alldocs[v2][doc_id]\n",
    "#print '\\n', simple_models['view2'][0].docvecs[tag]\n",
    "#print '\\n\\n', doc_list['view2'][:10]\n",
    "for model in simple_models:\n",
    "    inferred_docvec = model.infer_vector(alldocs[v1][doc_id].words)\n",
    "    print('%s:\\n %s' % (model, model.docvecs.most_similar([inferred_docvec], topn=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Select the best performing word2vec model\n",
    "_, best_alpha, best_model_name = min(((rate, alpha, name) \\\n",
    "                                           for name, (rate, alpha) in best_error[v1].items()), key=lambda b: b[0])\n",
    "print best_model_name \n",
    "print best_alpha\n",
    "best_model = models_by_name[best_model_name]\n",
    "\n",
    "# Train best model\n",
    "shuffle(doc_list)\n",
    "best_model.alpha, best_model.min_alpha = best_alpha, best_alpha\n",
    "best_model.train(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DO CCA on the training docvecs\n",
    "# X = view 1, Y = view 2 : [word_vec_size x num_samples]\n",
    "target_sentiments, X, Y = zip(*[(doc.sentiment, best_model.docvecs[doc.tags[0]], \\\n",
    "                             best_model.docvecs[doc.tags[0].replace(v1, v2)]) for doc in train_docs[v1]])\n",
    "X = np.asarray(X).T\n",
    "Y = np.asarray(Y).T\n",
    "#dev docs\n",
    "dev = [best_model.docvecs[doc.tags[0]] for doc in dev_docs[v1]]\n",
    "dev = np.asarray(dev).T\n",
    "#test docs\n",
    "test = [best_model.docvecs[doc.tags[0]] for doc in test_docs[v1]]\n",
    "test = np.asarray(test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(cca_eigval, cca_eigvec) = CCA(X, Y) #PLS(X, Y)  #kcca(X, Y, regX=0.1, regY=0.1, numCC=10, kernelcca=True, ktype=\"gaussian\")\n",
    "print np.shape(X), np.shape(Y)\n",
    "print np.shape(cca_eigvec)\n",
    "#print np.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_rate(X, X_targets, test, expected, print_conf=False):\n",
    "    predictor = predictor_alg(X_targets, X)\n",
    "\n",
    "    # predict & evaluate\n",
    "    predictions = predictor.predict(test)\n",
    "    predicted = np.rint(predictions)\n",
    "    #print(\"Classification report for %s:\\n%s\\n\" % (predictor, metrics.classification_report(expected, predicted)))\n",
    "    if print_conf:\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "    #ipdb.set_trace()\n",
    "    errors = len(predictions) - sum(expected == predicted)\n",
    "    err_orig = float(errors) / len(expected)\n",
    "    if print_conf:\n",
    "        print 1-err_orig\n",
    "    return (1-err_orig)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected = [doc.sentiment for doc in dev_docs[v1]]\n",
    "err_orig = error_rate(X.T, target_sentiments, dev.T, expected, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get top k eigvec, project training data and stack with original word vectors\n",
    "err_cca = []\n",
    "step = model_size/25\n",
    "num_dir_ranges = range(step, step+model_size, step)\n",
    "for num_dir in num_dir_ranges:\n",
    "    top_k_eigv = get_top_eigvec(cca_eigval, cca_eigvec, num_dir)\n",
    "    #print np.shape(top_k_eigv)\n",
    "    X_proj = top_k_eigv.T.dot(X)\n",
    "    #print np.shape(X_proj)\n",
    "    stacked_vec = np.append(X, X_proj, axis=0)\n",
    "    #print np.shape(stacked_vec)\n",
    "\n",
    "    # project test data to cca directions and stack\n",
    "    #print np.shape(test)\n",
    "    dev_proj = top_k_eigv.T.dot(dev)\n",
    "    stacked_dev = np.append(dev, dev_proj, axis=0)\n",
    "    #print np.shape(stacked_dev)\n",
    "    #print np.shape(target_sentiments)\n",
    "    \n",
    "    expected = [doc.sentiment for doc in dev_docs[v1]]\n",
    "    err_cca.append(error_rate(stacked_vec.T, target_sentiments, stacked_dev.T, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(num_dir_ranges, [err_orig]*len(num_dir_ranges), 'r--', label='Paragraph vec.')\n",
    "plt.plot(num_dir_ranges, err_cca, 'b*', label='Paragraph+CCA')\n",
    "plt.ylabel('Classification Accuracy(%)')\n",
    "plt.xlabel('Number of CCA directions stacked with paragraph vectors')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "corpus = [doc.words for doc in alldocs[v1]]\n",
    "tf_idf = vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.shape(tf_idf)\n",
    "tf_X = tf_idf[np.array([int(doc.tags[0].replace('_'+v1, '')) for doc in train_docs[v1]])]\n",
    "tf_dev = tf_idf[np.array([int(doc.tags[0].replace('_'+v1, '')) for doc in dev_docs[v1]])]\n",
    "tf_test = tf_idf[np.array([int(doc.tags[0].replace('_'+v1, '')) for doc in test_docs[v1]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected = [doc.sentiment for doc in dev_docs[v1]]\n",
    "#TF-IDF\n",
    "err_tf = error_rate(tf_X, target_sentiments, \\\n",
    "           tf_dev, expected, True)\n",
    "#Tf-IDF stacked with CCA\n",
    "err_tf_cca = []\n",
    "step = model_size/25\n",
    "num_dir_ranges = range(step, step+model_size, step)\n",
    "for num_dir in num_dir_ranges:\n",
    "    top_k_eigv = get_top_eigvec(cca_eigval, cca_eigvec, num_dir)\n",
    "    #print np.shape(top_k_eigv)\n",
    "    X_proj = top_k_eigv.T.dot(X)\n",
    "    #print np.shape(X_proj)\n",
    "    #stacked_vec = np.append(X, X_proj, axis=0)\n",
    "    #print np.shape(stacked_vec)\n",
    "\n",
    "    # project test data to cca directions and stack\n",
    "    #print np.shape(test)\n",
    "    dev_proj = top_k_eigv.T.dot(dev)\n",
    "    #stacked_dev = np.append(dev, dev_proj, axis=0)\n",
    "    #print np.shape(stacked_dev)\n",
    "    #print np.shape(target_sentiments)\n",
    "    err_tf_cca.append(error_rate(np.append(tf_X, X_proj.T, axis=1), target_sentiments, \\\n",
    "               np.append(tf_dev, dev_proj.T, axis=1), expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TF-IDF stacked with doc2vec\n",
    "expected = [doc.sentiment for doc in dev_docs[v1]]\n",
    "err_tf_doc = error_rate(np.append(tf_X, X.T, axis=1), target_sentiments, \\\n",
    "               np.append(tf_dev, dev.T, axis=1), expected, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(num_dir_ranges, [err_tf]*len(num_dir_ranges), 'r--', label='TF-IDF')\n",
    "plt.plot(num_dir_ranges, [err_tf_doc]*len(num_dir_ranges), 'g--', label='TF-IDF+Paragraph')\n",
    "plt.plot(num_dir_ranges, err_tf_cca, 'b*', label='TF-IDF+CCA')\n",
    "plt.ylabel('Classification Accuracy(%)')\n",
    "plt.xlabel('Number of CCA directions stacked with TF-IDF vectors')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test - TF-idf\n",
    "expected = [doc.sentiment for doc in test_docs[v1]]\n",
    "error_rate(tf_X, target_sentiments, tf_test, expected, True)\n",
    "#test - Doc2Vec stacked with tf-idf\n",
    "error_rate(np.append(tf_X, X.T, axis=1), target_sentiments, np.append(tf_test, test.T, axis=1), expected, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test tf-idf stacked with cca\n",
    "n = 50\n",
    "top_k_eigv = get_top_eigvec(cca_eigval, cca_eigvec, n)\n",
    "\n",
    "X_proj = top_k_eigv.T.dot(X)\n",
    "\n",
    "test_proj = top_k_eigv.T.dot(test)\n",
    "\n",
    "error_rate(np.append(tf_X, X_proj.T, axis=1), target_sentiments, \\\n",
    "           np.append(tf_test, test_proj.T, axis=1), expected, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
