{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data/view1_clean not found\n",
      "File: data/view2_clean not found\n",
      "File: data/test_clean not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#Split the all_views, get one file(sentiment, tweet) for each view\n",
    "#Clean each view\n",
    "#Run this for each view.\n",
    "norm() {\n",
    "    fn=$1\n",
    "    if [ ! -f \"$fn\" ]\n",
    "    then\n",
    "        echo \"File: $fn not found\"\n",
    "        return 0\n",
    "    fi\n",
    "    #this function will convert text to lowercase and will disconnect punctuation and special symbols from words\n",
    "    function normalize_text {\n",
    "        awk '{print tolower($0);}' < $1 | sed -e 's/\\./ \\. /g' -e 's/<br \\/>/ /g' -e 's/\"/ \" /g' \\\n",
    "        -e 's/,/ , /g' -e 's/(/ ( /g' -e 's/)/ ) /g' -e 's/\\!/ \\! /g' -e 's/\\?/ \\? /g' \\\n",
    "        -e 's/\\;/ \\; /g' -e 's/\\:/ \\: /g' > $1-norm\n",
    "    }\n",
    "    export LC_ALL=C\n",
    "    normalize_text \"$fn\"\n",
    "    wc -l $fn\n",
    "    mv \"$fn\" \"$fn-norm\"\n",
    "}\n",
    "norm \"data/view1_clean\" #file name is\n",
    "norm \"data/view2_clean\"\n",
    "norm \"data/test_clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "tw_view_1 = 'data/view1_clean-norm'\n",
    "tw_view_2 = 'data/view2_clean-norm'\n",
    "tw_test = 'data/test_clean-norm'\n",
    "assert os.path.isfile(tw_view_1), tw_view_1 + \" unavailable\"\n",
    "assert os.path.isfile(tw_view_2), tw_view_2 + \" unavailable\"\n",
    "assert os.path.isfile(tw_test), tw_test + \" unavailable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stem_document(doc_sentence):\n",
    "    words = doc_sentence.split()\n",
    "    stemmed = ' '.join([stemmer.stem(word) for word in words])\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4164 docs: 3045 train, 760 dev, 359 test\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple, defaultdict as dd\n",
    "\n",
    "#sentiment = {'positive':1, 'negative':-1} #, 'neutral':2}\n",
    "sentiment_dict = {'4':1, '0':-1} #- new data 0,4\n",
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags split sentiment')\n",
    "stem = False\n",
    "\n",
    "alldocs = dd(list)  # will hold all docs in original order - dictionary, keys = [v1, v2]\n",
    "v1 = 'view1'\n",
    "v2 = 'view2'\n",
    "#tw_sentiment_dict = {}\n",
    "#print total_num, train_test_shuffle\n",
    "all_v2_words = []\n",
    "with open(tw_view_2) as allview2:\n",
    "        all_v2_words = allview2.readlines()\n",
    "total_num = len(all_v2_words)\n",
    "#split train/test\n",
    "train_num = total_num *  8 / 10 # 70% train/test 1 - 10\n",
    "train_test_shuffle = np.arange(total_num)\n",
    "np.random.shuffle(train_test_shuffle)\n",
    "with open(tw_view_1) as allview1:\n",
    "    #for line_no, (v1, v2) in enumerate(zip(allview1, allview2)):\n",
    "    for line_no, line in enumerate(allview1):\n",
    "        tokens = gensim.utils.to_unicode(line).split('\\t')\n",
    "        if len(tokens) != 2:\n",
    "            print line\n",
    "            raise Exception()\n",
    "        sentiment = sentiment_dict[tokens[0]]\n",
    "        #if tw_id not in tw_sentiment_dict.keys():\n",
    "        #    continue\n",
    "        words = tokens[1]\n",
    "        split = 'train' if train_test_shuffle[line_no] <= train_num else 'dev'\n",
    "        #sentiment = tw_sentiment_dict[tw_id]\n",
    "        v2_words = gensim.utils.to_unicode(all_v2_words[line_no]).split('\\t')[1]\n",
    "        \n",
    "        alldocs[v1].append(SentimentDocument(stem_document(words) if stem else words, [line_no], split, sentiment))\n",
    "        alldocs[v2].append(SentimentDocument(stem_document(v2_words) if stem else v2_words, [line_no], split, sentiment))\n",
    "# test file\n",
    "with open(tw_test) as test_fh:\n",
    "    for line_no, line in enumerate(test_fh):\n",
    "        tokens = gensim.utils.to_unicode(line).split('\\t')\n",
    "        if len(tokens) != 2:\n",
    "            print line\n",
    "            raise Exception()\n",
    "        sentiment = sentiment_dict[tokens[0]]\n",
    "        #if tw_id not in tw_sentiment_dict.keys():\n",
    "        #    continue\n",
    "        words = tokens[1]\n",
    "        split = 'test'\n",
    "        \n",
    "        alldocs[v1].append(SentimentDocument(stem_document(words) if stem else words, \\\n",
    "                                             [total_num+line_no], split, sentiment))\n",
    "train_docs = {\n",
    "    v1 : [doc for doc in alldocs[v1] if doc.split == 'train'],\n",
    "    v2 : [doc for doc in alldocs[v2] if doc.split == 'train']\n",
    "}\n",
    "dev_docs = {\n",
    "    v1 : [doc for doc in alldocs[v1] if doc.split == 'dev'],\n",
    "    v2 : [doc for doc in alldocs[v2] if doc.split == 'dev']\n",
    "}\n",
    "test_docs = {\n",
    "    v1 : [doc for doc in alldocs[v1] if doc.split == 'test'],\n",
    "    v2 : [doc for doc in alldocs[v2] if doc.split == 'test']\n",
    "}\n",
    "doc_list = { v1: alldocs[v1][:], v2: alldocs[v2][:] }  # for reshuffling per pass\n",
    "\n",
    "print('%d docs: %d train, %d dev, %d test' % (len(doc_list[v1]), len(train_docs[v1]), len(dev_docs[v1]), len(test_docs[v1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view1 Doc2Vec(dm/c,d1000,n5,w3,mc2,t4)\n",
      "view1 Doc2Vec(dbow,d1000,n5,mc5,t4)\n",
      "view1 Doc2Vec(dm/m,d1000,n5,w3,mc2,t4)\n",
      "view2 Doc2Vec(dm/c,d1000,n5,w3,mc2,t4)\n",
      "view2 Doc2Vec(dbow,d1000,n5,mc5,t4)\n",
      "view2 Doc2Vec(dm/m,d1000,n5,w3,mc2,t4)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"this will be painfully slow otherwise\"\n",
    "model_size = 1000\n",
    "simple_models , models_by_name = {}, {} \n",
    "for view in [v1, v2]:\n",
    "    simple_models[view] = [\n",
    "        # PV-DM w/concatenation - window=5 (both sides) approximates paper's 10-word total window size\n",
    "        Doc2Vec(dm=1, dm_concat=1, size=model_size, window=3, negative=5, hs=0, min_count=2, workers=cores),\n",
    "        # PV-DBOW \n",
    "        Doc2Vec(dm=0, size=model_size, negative=5, hs=0, min_count=5, workers=cores),\n",
    "        # PV-DM w/average\n",
    "        Doc2Vec(dm=1, dm_mean=1, size=model_size, window=3, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    ]\n",
    "\n",
    "    # speed setup by sharing results of 1st model's vocabulary scan\n",
    "    simple_models[view][0].build_vocab(alldocs[view])  # PV-DM/concat requires one special NULL word so it serves as template\n",
    "    print view, simple_models[view][0]\n",
    "    for model in simple_models[view][1:]:\n",
    "        model.reset_from(simple_models[view][0])\n",
    "        print view, model\n",
    "\n",
    "    models_by_name[view] = OrderedDict((str(model), model) for model in simple_models[view])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "for view in [v1, v2]:\n",
    "    models_by_name[view]['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[view][1], simple_models[view][2]])\n",
    "    models_by_name[view]['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[view][1], simple_models[view][0]])\n",
    "#print models_by_name['dbow+dmm'], models_by_name['dbow+dmc'] \n",
    "#del models_by_name['dbow+dmc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn import svm, metrics, neighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from random import sample\n",
    "\n",
    "# for timing\n",
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "import time \n",
    "import ipdb\n",
    "\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = default_timer()\n",
    "    elapser = lambda: default_timer() - start\n",
    "    yield lambda: elapser()\n",
    "    end = default_timer()\n",
    "    elapser = lambda: end-start\n",
    "    \n",
    "def logistic_predictor(train_targets, train_regressors):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train_regressors, train_targets)\n",
    "    return lr\n",
    "\n",
    "def svm_predictor(train_targets, train_regressors):\n",
    "    svc = svm.SVC(kernel='rbf', degree=5, gamma=1e-1)\n",
    "    svc.fit(train_regressors, train_targets)\n",
    "    return svc\n",
    "\n",
    "    \"\"\"expected = svm_y_test\n",
    "    predicted = svc.predict(svm_x_test)\n",
    "\n",
    "    #print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "    #      % (svc, metrics.classification_report(expected, predicted)))\n",
    "    #print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "    \"\"\"\n",
    "def rf_predictor(train_targets, train_regressors):\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "    rfc.fit(train_regressors, train_targets)\n",
    "    return rfc\n",
    "\n",
    "def error_rate_for_model(test_model, train_set, test_set, infer=False, infer_steps=3, infer_alpha=0.1, infer_subsample=0.1):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets, train_regressors = zip(*[(doc.sentiment, test_model.docvecs[doc.tags[0]]) for doc in train_set])\n",
    "    #train_regressors = sm.add_constant(train_regressors)\n",
    "    predictor = logistic_predictor(train_targets, train_regressors)\n",
    "    #predictor = svm_predictor(train_targets, train_regressors)\n",
    "\n",
    "    test_data = test_set\n",
    "    if infer:\n",
    "        if infer_subsample < 1.0:\n",
    "            test_data = sample(test_data, int(infer_subsample * len(test_data)))\n",
    "        test_regressors = [test_model.infer_vector(doc.words, steps=infer_steps, alpha=infer_alpha) for doc in test_data]\n",
    "    else:\n",
    "        test_regressors = [test_model.docvecs[doc.tags[0]] for doc in test_data]\n",
    "    \n",
    "    # predict & evaluate\n",
    "    test_predictions = predictor.predict(test_regressors)\n",
    "    predicted = np.rint(test_predictions)\n",
    "    expected = [doc.sentiment for doc in test_data]\n",
    "    \"\"\"if not infer:\n",
    "        print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "              % (predictor, metrics.classification_report(expected, predicted)))\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\"\"\"\n",
    "    #ipdb.set_trace()\n",
    "    corrects = sum(expected == predicted)\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.linalg import eigh\n",
    "%matplotlib inline\n",
    "def center(data):\n",
    "    return data - np.mean(data, axis=0)\n",
    "\n",
    "def PLS(X, Y):\n",
    "    cross_cov = np.dot(center(X), center(Y).T)\n",
    "    eigval,eigvec=np.linalg.eig(cross_cov.dot(cross_cov.T))\n",
    "    return (eigval, eigvec)\n",
    "\n",
    "def PLS_MFCC():\n",
    "    dims = [10, 30, 50, 70, 90, 110]\n",
    "    accuracies = np.zeros((len(num_neighb), len(dims)))\n",
    "    # (score, dim, k, PLS_subspace, classifier_object)\n",
    "    best = (0, 0, 0, None, None)\n",
    "    #run pls\n",
    "    eigval, U = PLS(acoustic_train, artic_train)\n",
    "    for j, k in enumerate(num_neighb):\n",
    "        for i, d in enumerate(dims):\n",
    "            U_d = get_top_eigvec(eigval, U, d)\n",
    "            #get projection to pls space\n",
    "            train_proj = np.dot(U_d.T, acoustic_train_cen)\n",
    "            dev_proj = np.dot(U_d.T, acoustic_dev_cen)\n",
    "            # stack with mfcc39\n",
    "            stacked_train = np.append(train_proj, mfcc39_train, axis=0)\n",
    "            stacked_dev = np.append(dev_proj, mfcc39_dev, axis=0)\n",
    "\n",
    "            #classify\n",
    "            clf = neighbors.KNeighborsClassifier(k)\n",
    "            clf.fit(stacked_train.T, phones_train)\n",
    "\n",
    "            #predictions\n",
    "            score = clf.score(stacked_dev.T, phones_dev)\n",
    "            if score > best[0]:\n",
    "                best = (score, d, k, U_d, clf)\n",
    "            accuracies[j,i] = score\n",
    "    return (best, accuracies)\n",
    "\n",
    "def kcca(X, Y, regX=0.1, regY=0.1, numCC=10, kernelcca=True, ktype=\"gaussian\"):\n",
    "    '''Set up and solve the eigenproblem for the data in kernel and specified reg\n",
    "    '''\n",
    "    cenX = center(X)\n",
    "    cenY = center(Y)\n",
    "    kernel1 = np.array([_make_kernel(X.T, ktype=ktype)])\n",
    "    kernel_x = (kernel1 + kernel1.T)/2\n",
    "    kernel2 = np.array([_make_kernel(Y.T, ktype=ktype)])\n",
    "    kernel_y = (kernel2 + kernel2.T)/2\n",
    "    r_Ix = regX * np.eye(kernel_x.shape[0])\n",
    "    r_Iy = regY * np.eye(kernel_y.shape[0])\n",
    "    A = reduce(np.dot, [ np.linalg.inv(kernel_x - r_Ix), kernel_y, np.linalg.inv(kernel_y - r_Iy), kernel_x])\n",
    "    eigval,eigvec=np.linalg.eig(A)\n",
    "    return (eigval, eigvec)\n",
    "\n",
    "def _listcorr(a):\n",
    "    '''Returns pairwise row correlations for all items in array as a list of matrices\n",
    "    '''\n",
    "    corrs = np.zeros((a[0].shape[1], len(a), len(a)))\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(a)):\n",
    "            if j > i:\n",
    "                corrs[:, i, j] = [np.nan_to_num(np.corrcoef(ai, aj)[0, 1]) for (ai, aj) in zip(a[i].T, a[j].T)]\n",
    "    return corrs\n",
    "\n",
    "\n",
    "def recon(data, comp, corronly=False, kernelcca=True):\n",
    "    nT = data[0].shape[0]\n",
    "    # Get canonical variates and CCs\n",
    "    if kernelcca:\n",
    "        ws = _listdot(data, comp)\n",
    "    else:\n",
    "        ws = comp\n",
    "    ccomp = _listdot([d.T for d in data], ws)\n",
    "    corrs = _listcorr(ccomp)\n",
    "    if corronly:\n",
    "        return corrs\n",
    "    else:\n",
    "        return corrs, ws, ccomp\n",
    "\n",
    "\n",
    "def _listdot(d1, d2): return [np.dot(x[0].T, x[1]) for x in zip(d1, d2)]\n",
    "\n",
    "\n",
    "def _make_kernel(d, normalize=True, ktype=\"linear\", sigma=1.0):\n",
    "    '''Makes a kernel for data d\n",
    "      If ktype is \"linear\", the kernel is a linear inner product\n",
    "      If ktype is \"gaussian\", the kernel is a Gaussian kernel with sigma = sigma\n",
    "    '''\n",
    "    if ktype == \"linear\":\n",
    "        d = np.nan_to_num(d)\n",
    "        cd = _demean(d)\n",
    "        kernel = np.dot(cd, cd.T)\n",
    "    elif ktype == \"gaussian\":\n",
    "        from scipy.spatial.distance import pdist, squareform\n",
    "        # this is an NxD matrix, where N is number of items and D its dimensionalites\n",
    "        pairwise_dists = squareform(pdist(d, 'euclidean'))\n",
    "        kernel = np.exp(-pairwise_dists ** 2 / sigma ** 2)\n",
    "    kernel = (kernel + kernel.T) / 2.\n",
    "    kernel = kernel / np.linalg.eigvalsh(kernel).max()\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def _demean(d): return d - d.mean(0)\n",
    "\n",
    "def CCA(X, Y, regX = 0, regY = 0):\n",
    "    cenX = center(X)\n",
    "    cenY = center(Y)\n",
    "    cross_cov = cenX.dot(cenY.T)\n",
    "    covX = cenX.dot(cenX.T)\n",
    "    covY = cenY.dot(cenY.T)\n",
    "    r_Ix = regX * np.eye(covX.shape[0])\n",
    "    r_Iy = regY * np.eye(covY.shape[0])\n",
    "    A = reduce(np.dot, [ np.linalg.inv(covX + r_Ix), cross_cov, np.linalg.inv(covY + r_Iy), cross_cov.T ])\n",
    "    eigval,eigvec=np.linalg.eig(A)\n",
    "    return (eigval, eigvec)\n",
    "\n",
    "def get_top_eigvec(eigval, eigvec, k):\n",
    "    idx=np.argsort(eigval)[-k:][::-1]\n",
    "    #eigval=eigval[idx]\n",
    "    return eigvec[:,idx]\n",
    "\n",
    "def CCA_MFCC():\n",
    "    dims = [10, 30, 50, 70, 90, 110]\n",
    "    reg = [1e-8, 1e-6, 1e-4, 1e-2, 1e-1, 1e1]\n",
    "    accuracies = np.zeros((len(reg), len(reg), len(dims), len(num_neighb)))\n",
    "    # (score, dim, regX, regY, k, CCA_subspace, classifier_object)\n",
    "    best = (0, 0, 0, 0, 0, None, None)\n",
    "    for rx, regX in enumerate(reg):\n",
    "        for ry, regY in enumerate(reg):\n",
    "            #run cca\n",
    "            eigval, U = CCA(acoustic_train, artic_train, regX, regY)\n",
    "            for i, d in enumerate(dims):\n",
    "                U_d = get_top_eigvec(eigval, U, d)\n",
    "                #get projection to cca space\n",
    "                train_proj = U_d.T.dot(acoustic_train_cen)\n",
    "                dev_proj = U_d.T.dot(acoustic_dev_cen)\n",
    "                # stack with mfcc39\n",
    "                stacked_train = np.append(train_proj, mfcc39_train, axis=0)\n",
    "                stacked_dev = np.append(dev_proj, mfcc39_dev, axis=0)\n",
    "                #classify\n",
    "                for j, k in enumerate(num_neighb):\n",
    "                    clf = neighbors.KNeighborsClassifier(k)\n",
    "                    clf.fit(stacked_train.T, phones_train)\n",
    "\n",
    "                    #predictions\n",
    "                    score = clf.score(stacked_dev.T, phones_dev)\n",
    "                    if score > best[0]:\n",
    "                        best = (score, d, regX, regY, k, U_d, clf)\n",
    "                    accuracies[rx, ry, i, j] = score\n",
    "    return (best, accuracies)\n",
    "\n",
    "def plot_pc2(data, eigvec, phones_data):\n",
    "    #project to top 2 princ. comp.\n",
    "    data_proj = np.dot(np.transpose(eigvec), data)\n",
    "    data_proj_labels=[data_proj[:,np.where(phones_data==lbl)] for lbl in labels_dict.values()]\n",
    "    #Plot\n",
    "    cmap = plt.get_cmap('jet_r')\n",
    "    N=len(labels)\n",
    "    colors = [cmap(float(i)/N) for i in np.linspace(5.0, 0, N)]\n",
    "    plt.figure(figsize=(7,7))\n",
    "    #plt.subplot(2,1,1)\n",
    "    for i in range(N):\n",
    "        plt.scatter(data_proj_labels[i][0,:], data_proj_labels[i][1,:] ,c=colors[i], marker='+', label=labels[i]);\n",
    "    #plt.legend(plots,labels)\n",
    "    plt.legend(loc=3)\n",
    "    #plt.show()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from collections import defaultdict\n",
    "best_error = dd(lambda: dd(lambda :(1.0, 0.0))) # { view: { model_name : (error_rate, alpha) } } ,to selectively-print only best errors achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started.\n",
      "======== view1 =========\n",
      "START 2015-12-15 01:02:30.643899\n",
      "END 2015-12-15 01:03:47.596074\n",
      "======== view2 =========\n",
      "START 2015-12-15 01:03:47.596473\n",
      "END 2015-12-15 01:04:59.581903\n"
     ]
    }
   ],
   "source": [
    "predictor_alg = logistic_predictor\n",
    "#predictor_alg = svm_predictor\n",
    "from random import shuffle\n",
    "import datetime\n",
    "\n",
    "print 'Started.'\n",
    "for view in [v1, v2]:\n",
    "    alpha, min_alpha, passes = (0.025, 0.001, 10)\n",
    "    alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "    print \"======== %s =========\" %view\n",
    "    print(\"START %s\" % datetime.datetime.now())\n",
    "\n",
    "    for epoch in range(passes):\n",
    "        shuffle(doc_list[view])  # shuffling gets best results\n",
    "\n",
    "        for name, train_model in models_by_name[view].items():\n",
    "            #print name\n",
    "            # train\n",
    "            duration = 'na'\n",
    "            train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "            with elapsed_timer() as elapsed:\n",
    "                train_model.train(doc_list[view])\n",
    "                duration = '%.1f' % elapsed()\n",
    "\n",
    "            # evaluate\n",
    "            eval_duration = ''\n",
    "            with elapsed_timer() as eval_elapsed:\n",
    "                err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs[view], dev_docs[view])\n",
    "            eval_duration = '%.1f' % eval_elapsed()\n",
    "            best_indicator = ' '\n",
    "            if err < best_error[view][name][0]:\n",
    "                best_error[view][name] = (err, alpha)\n",
    "                best_indicator = '*' \n",
    "            #print(\"%s%f : %i passes : %s-%s %ss %ss\" % (best_indicator, err, epoch + 1, view, name, duration, eval_duration))\n",
    "\n",
    "            \"\"\"if ((epoch + 1) % 5) == 0 or epoch == 0:\n",
    "                eval_duration = ''\n",
    "                with elapsed_timer() as eval_elapsed:\n",
    "                    infer_err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs[view], test_docs[view], infer=True)\n",
    "                eval_duration = '%.1f' % eval_elapsed()\n",
    "                best_indicator = ' '\n",
    "                if infer_err < best_error[view][name + '_inferred'][0]:\n",
    "                    best_error[view][name + '_inferred'] = (infer_err, alpha)\n",
    "                    best_indicator = '*'\n",
    "                print(\"%s%f : %i passes : %s-%s %ss %ss\" % (best_indicator, infer_err, epoch + 1, view, name + '_inferred', duration, eval_duration))\n",
    "\"\"\"\n",
    "        #print('completed pass %i at alpha %f' % (epoch + 1, alpha))\n",
    "        alpha -= alpha_delta\n",
    "\n",
    "    print(\"END %s\" % str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= view1 ========\n",
      "0.405263 Doc2Vec(dbow,d1000,n5,mc5,t4) 0.003400\n",
      "0.409211 dbow+dmc 0.022600\n",
      "0.417105 dbow+dmm 0.010600\n",
      "0.446053 Doc2Vec(dm/c,d1000,n5,w3,mc2,t4) 0.025000\n",
      "0.456579 Doc2Vec(dm/m,d1000,n5,w3,mc2,t4) 0.025000\n",
      "========= view2 ========\n",
      "0.432895 dbow+dmm 0.015400\n",
      "0.442105 Doc2Vec(dm/c,d1000,n5,w3,mc2,t4) 0.020200\n",
      "0.444737 Doc2Vec(dbow,d1000,n5,mc5,t4) 0.025000\n",
      "0.447368 dbow+dmc 0.025000\n",
      "0.448684 Doc2Vec(dm/m,d1000,n5,w3,mc2,t4) 0.013000\n"
     ]
    }
   ],
   "source": [
    "for view in [v1, v2]:\n",
    "    print '========= %s ========' %view\n",
    "    for rate, alpha, name in sorted((rate, alpha, name) for name, (rate, alpha) in best_error[view].items()):\n",
    "        print(\"%f %s %f\" % (rate, name, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for doc 2355...\n",
      "SentimentDocument(words=u'Listening to Arcade Fire and feeling summery.   Tiiight.\\n', tags=[2355], split='train', sentiment=1)\n",
      "\n",
      "SentimentDocument(words=u'Three days off starting tomorrow!  I must shout it on the mountain tops!\\n', tags=[2355], split='train', sentiment=1)\n",
      "Doc2Vec(dm/c,d1000,n5,w3,mc2,t4):\n",
      " [(752, 0.8797434568405151), (3810, 0.8581063747406006), (2355, 0.8279649019241333)]\n",
      "Doc2Vec(dbow,d1000,n5,mc5,t4):\n",
      " [(2355, 0.8581156730651855), (1940, 0.7756696939468384), (4163, 0.7744331359863281)]\n",
      "Doc2Vec(dm/m,d1000,n5,w3,mc2,t4):\n",
      " [(1864, 0.6954625844955444), (3578, 0.679758608341217), (2270, 0.6741034984588623)]\n"
     ]
    }
   ],
   "source": [
    "doc_id = np.random.randint(simple_models[v2][0].docvecs.count)  # pick random doc; re-run cell for more examples\n",
    "print('for doc %d...' % doc_id)\n",
    "# Print example tweet and vector reps for both views\n",
    "print alldocs['view1'][doc_id]\n",
    "#tag = alldocs['view1'][doc_id].tags[0]\n",
    "#print '\\n', simple_models['view1'][0].docvecs[tag]\n",
    "\n",
    "print '\\n', alldocs['view2'][doc_id]\n",
    "#print '\\n', simple_models['view2'][0].docvecs[tag]\n",
    "#print '\\n\\n', doc_list['view2'][:10]\n",
    "for model in simple_models[v1]:\n",
    "    inferred_docvec = model.infer_vector(alldocs[v1][doc_id].words)\n",
    "    print('%s:\\n %s' % (model, model.docvecs.most_similar([inferred_docvec], topn=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for doc 2889...\n",
      "Doc2Vec(dm/c,d1000,n5,w3,mc2,t4):\n",
      " [(3913, 0.7146048545837402), (3996, 0.7137438058853149), (2971, 0.6974024772644043)]\n",
      "Doc2Vec(dbow,d1000,n5,mc5,t4):\n",
      " [(2889, 0.8416193127632141), (2990, 0.665088951587677), (3946, 0.6605066061019897)]\n",
      "Doc2Vec(dm/m,d1000,n5,w3,mc2,t4):\n",
      " [(1158, 0.7685563564300537), (2889, 0.7611678838729858), (2284, 0.7105810046195984)]\n"
     ]
    }
   ],
   "source": [
    "doc_id = np.random.randint(simple_models[v2][0].docvecs.count)  # pick random doc; re-run cell for more examples\n",
    "print('for doc %d...' % doc_id)\n",
    "for model in simple_models[v1]:\n",
    "    inferred_docvec = model.infer_vector(alldocs[v1][doc_id].words)\n",
    "    print('%s:\\n %s' % (model, model.docvecs.most_similar([inferred_docvec], topn=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d1000,n5,mc5,t4)\n",
      "0.0034\n"
     ]
    }
   ],
   "source": [
    "#Select the best performing word2vec model\n",
    "_, best_alpha, best_model_name = min(((rate, alpha, name) \\\n",
    "                                           for name, (rate, alpha) in best_error[v1].items()), key=lambda b: b[0])\n",
    "print best_model_name \n",
    "print best_alpha\n",
    "best_model = { v1 : models_by_name[v1][best_model_name],\n",
    "              v2 : models_by_name[v2][best_model_name] }\n",
    "# Train best model\n",
    "shuffle(doc_list[view])\n",
    "for view in [v1, v2]:\n",
    "    best_model[view].alpha, best_model[view].min_alpha = best_alpha, best_alpha\n",
    "    best_model[view].train(doc_list[view])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DO CCA on the training docvecs\n",
    "# X = view 1, Y = view 2 : [word_vec_size x num_samples]\n",
    "target_sentiments, X, Y = zip(*[(doc.sentiment, best_model[v1].docvecs[doc.tags[0]], \\\n",
    "                             best_model[v2].docvecs[doc.tags[0]]) for doc in train_docs[v1]])\n",
    "X = np.asarray(X).T\n",
    "Y = np.asarray(Y).T\n",
    "#dev docs\n",
    "dev = [best_model[v1].docvecs[doc.tags[0]] for doc in dev_docs[v1]]\n",
    "dev = np.asarray(dev).T\n",
    "#test docs\n",
    "test = [best_model[v1].docvecs[doc.tags[0]] for doc in test_docs[v1]]\n",
    "test = np.asarray(test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3045) (1000, 3045)\n",
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "(cca_eigval, cca_eigvec) = CCA(X, Y)  #kcca(X, Y, regX=0.1, regY=0.1, numCC=10, kernelcca=True, ktype=\"gaussian\")\n",
    "print np.shape(X), np.shape(Y)\n",
    "print np.shape(cca_eigvec)\n",
    "#print np.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_rate(X, X_targets, test, expected, print_conf=False):\n",
    "    predictor = logistic_predictor(X_targets, X)\n",
    "\n",
    "    # predict & evaluate\n",
    "    predictions = predictor.predict(test)\n",
    "    predicted = np.rint(predictions)\n",
    "    #print(\"Classification report for %s:\\n%s\\n\" % (predictor, metrics.classification_report(expected, predicted)))\n",
    "    if print_conf:\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "    #ipdb.set_trace()\n",
    "    errors = len(predictions) - sum(expected == predicted)\n",
    "    err_orig = float(errors) / len(expected)\n",
    "    if print_conf:\n",
    "        print err_orig\n",
    "    return err_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[164 175]\n",
      " [137 284]]\n",
      "0.410526315789\n"
     ]
    }
   ],
   "source": [
    "expected = [doc.sentiment for doc in dev_docs[v1]]\n",
    "err_orig = error_rate(X.T, target_sentiments, dev.T, expected, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get top k eigvec, project training data and stack with original word vectors\n",
    "err_cca = []\n",
    "step = 50\n",
    "num_dir_ranges = range(step, step+model_size, step)\n",
    "for num_dir in num_dir_ranges:\n",
    "    top_k_eigv = get_top_eigvec(cca_eigval, cca_eigvec, num_dir)\n",
    "    #print np.shape(top_k_eigv)\n",
    "    X_proj = top_k_eigv.T.dot(X)\n",
    "    #print np.shape(X_proj)\n",
    "    stacked_vec = np.append(X, X_proj, axis=0)\n",
    "    #print np.shape(stacked_vec)\n",
    "\n",
    "    # project test data to cca directions and stack\n",
    "    #print np.shape(test)\n",
    "    dev_proj = top_k_eigv.T.dot(dev)\n",
    "    stacked_dev = np.append(dev, dev_proj, axis=0)\n",
    "    #print np.shape(stacked_dev)\n",
    "    #print np.shape(target_sentiments)\n",
    "\n",
    "    predictor = logistic_predictor(target_sentiments, stacked_vec.T)\n",
    "\n",
    "    # predict & evaluate\n",
    "    dev_predictions = predictor.predict(stacked_dev.T)\n",
    "    predicted = np.rint(dev_predictions)\n",
    "    expected = [doc.sentiment for doc in dev_docs[v1]]\n",
    "    #print(\"Classification report for %s:\\n%s\\n\" % (predictor, metrics.classification_report(expected, predicted)))\n",
    "    #print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "    #ipdb.set_trace()\n",
    "    errors = len(dev_predictions) - sum(expected == predicted)\n",
    "    err_cca.append(float(errors) / len(expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEPCAYAAAAEfBBiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1oa65V0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f7df590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_dir_ranges, [err_orig]*len(num_dir_ranges), 'r--', num_dir_ranges, err_cca, 'b*')\n",
    "plt.ylabel('Mis-classification rate')\n",
    "plt.xlabel('Number of CCA directions stacked with original sentence vectors')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 62 115]\n",
      " [ 36 146]]\n",
      "0.42061281337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4206128133704735"
      ]
     },
     "execution_count": 1231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test - doc2vec\n",
    "expected = [doc.sentiment for doc in test_docs[v1]]\n",
    "error_rate(X.T, target_sentiments, test.T, expected, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 62 115]\n",
      " [ 36 146]]\n",
      "0.42061281337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4206128133704735"
      ]
     },
     "execution_count": 1232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test doc2vec stacked with cca\n",
    "top_k_eigv = get_top_eigvec(cca_eigval, cca_eigvec, 400)\n",
    "#print np.shape(top_k_eigv)\n",
    "X_proj = top_k_eigv.T.dot(X)\n",
    "#print np.shape(X_proj)\n",
    "stacked_vec = np.append(X, X_proj, axis=0)\n",
    "#print np.shape(stacked_vec)\n",
    "\n",
    "# project test data to cca directions and stack\n",
    "#print np.shape(test)\n",
    "test_proj = top_k_eigv.T.dot(test)\n",
    "stacked_test = np.append(test, test_proj, axis=0)\n",
    "#print np.shape(stacked_test)\n",
    "#print np.shape(target_sentiments)\n",
    "\n",
    "expected = [doc.sentiment for doc in test_docs[v1]]\n",
    "error_rate(stacked_vec.T, target_sentiments, stacked_test.T, expected, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "corpus = [doc.words for doc in alldocs[v1]]\n",
    "tf_idf = vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(tf_idf)\n",
    "tf_X = tf_idf[np.array([doc.tags[0] for doc in train_docs[v1]])]\n",
    "tf_dev = tf_idf[np.array([doc.tags[0] for doc in dev_docs[v1]])]\n",
    "tf_test = tf_idf[np.array([doc.tags[0] for doc in test_docs[v1]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[215 124]\n",
      " [ 95 326]]\n",
      "0.288157894737\n"
     ]
    }
   ],
   "source": [
    "expected = [doc.sentiment for doc in dev_docs[v1]]\n",
    "#TF-IDF\n",
    "err_tf = error_rate(tf_X, target_sentiments, \\\n",
    "           tf_dev, expected, True)\n",
    "#Tf-IDF stacked with CCA\n",
    "err_tf_cca = []\n",
    "step = 50\n",
    "num_dir_ranges = range(step, step+model_size, step)\n",
    "for num_dir in num_dir_ranges:\n",
    "    top_k_eigv = get_top_eigvec(cca_eigval, cca_eigvec, num_dir)\n",
    "    #print np.shape(top_k_eigv)\n",
    "    X_proj = top_k_eigv.T.dot(X)\n",
    "    #print np.shape(X_proj)\n",
    "    stacked_vec = np.append(X, X_proj, axis=0)\n",
    "    #print np.shape(stacked_vec)\n",
    "\n",
    "    # project test data to cca directions and stack\n",
    "    #print np.shape(test)\n",
    "    dev_proj = top_k_eigv.T.dot(dev)\n",
    "    stacked_dev = np.append(dev, dev_proj, axis=0)\n",
    "    #print np.shape(stacked_dev)\n",
    "    #print np.shape(target_sentiments)\n",
    "    err_tf_cca.append(error_rate(np.append(tf_X, X_proj.T, axis=1), target_sentiments, \\\n",
    "               np.append(tf_dev, dev_proj.T, axis=1), expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[206 133]\n",
      " [ 97 324]]\n",
      "0.302631578947\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF stacked with doc2vec\n",
    "err_tf_doc = error_rate(np.append(tf_X, X.T, axis=1), target_sentiments, \\\n",
    "               np.append(tf_dev, dev.T, axis=1), expected, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEPCAYAAACQmrmQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGhcyZmZWmv8PI6HHNJt4MqIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112fe5dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_dir_ranges, [err_tf]*len(num_dir_ranges), 'r--', num_dir_ranges, \\\n",
    "         [err_tf_doc]*len(num_dir_ranges), 'g--', num_dir_ranges, err_tf_cca, 'b*')\n",
    "plt.ylabel('Mis-classification rate')\n",
    "plt.xlabel('Number of CCA directions stacked with original sentence vectors')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
