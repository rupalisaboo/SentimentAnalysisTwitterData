{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data/view1_clean not found\n",
      "File: data/view2_clean not found\n",
      "File: data/test_clean not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#Split the all_views, get one file(sentiment, tweet) for each view\n",
    "#Clean each view\n",
    "#Run this for each view.\n",
    "norm() {\n",
    "    fn=$1\n",
    "    if [ ! -f \"$fn\" ]\n",
    "    then\n",
    "        echo \"File: $fn not found\"\n",
    "        return 0\n",
    "    fi\n",
    "    #this function will convert text to lowercase and will disconnect punctuation and special symbols from words\n",
    "    function normalize_text {\n",
    "        awk '{print tolower($0);}' < $1 | sed -e 's/\\./ \\. /g' -e 's/<br \\/>/ /g' -e 's/\"/ \" /g' \\\n",
    "        -e 's/,/ , /g' -e 's/(/ ( /g' -e 's/)/ ) /g' -e 's/\\!/ \\! /g' -e 's/\\?/ \\? /g' \\\n",
    "        -e 's/\\;/ \\; /g' -e 's/\\:/ \\: /g' > $1-norm\n",
    "    }\n",
    "    export LC_ALL=C\n",
    "    normalize_text \"$fn\"\n",
    "    wc -l $fn\n",
    "    mv \"$fn\" \"$fn-norm\"\n",
    "}\n",
    "norm \"data/view1_clean\" #file name is\n",
    "norm \"data/view2_clean\"\n",
    "norm \"data/test_clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "tw_view_1 = 'data/view1_clean-norm'\n",
    "tw_view_2 = 'data/view2_clean-norm'\n",
    "tw_test = 'data/test_clean-norm'\n",
    "assert os.path.isfile(tw_view_1), tw_view_1 + \" unavailable\"\n",
    "assert os.path.isfile(tw_view_2), tw_view_2 + \" unavailable\"\n",
    "assert os.path.isfile(tw_test), tw_test + \" unavailable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stem_document(doc_sentence):\n",
    "    words = doc_sentence.split()\n",
    "    stemmed = ' '.join([stemmer.stem(word) for word in words])\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4164 docss: 3045 train, 760 dev, 359 test\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "#from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple, defaultdict as dd\n",
    "\n",
    "#sentiment = {'positive':1, 'negative':-1} #, 'neutral':2}\n",
    "sentiment_dict = {'4':1, '0':-1} #- new data 0,4\n",
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags split sentiment')\n",
    "stem = True\n",
    "\n",
    "alldocs = dd(list)  # will hold all docs in original order - dictionary, keys = [v1, v2]\n",
    "v1 = 'view1'\n",
    "v2 = 'view2'\n",
    "#tw_sentiment_dict = {}\n",
    "#print total_num, train_test_shuffle\n",
    "all_v2_words = []\n",
    "with open(tw_view_2) as allview2:\n",
    "        all_v2_words = allview2.readlines()\n",
    "total_num = len(all_v2_words)\n",
    "#split train/test\n",
    "train_num = total_num *  8 / 10 # 70% train/test 1 - 10\n",
    "train_test_shuffle = np.arange(total_num)\n",
    "np.random.shuffle(train_test_shuffle)\n",
    "with open(tw_view_1) as allview1:\n",
    "    #for line_no, (v1, v2) in enumerate(zip(allview1, allview2)):\n",
    "    for line_no, line in enumerate(allview1):\n",
    "        tokens = gensim.utils.to_unicode(line).split('\\t')\n",
    "        if len(tokens) != 2:\n",
    "            print line\n",
    "            raise Exception()\n",
    "        sentiment = sentiment_dict[tokens[0]]\n",
    "        #if tw_id not in tw_sentiment_dict.keys():\n",
    "        #    continue\n",
    "        words = tokens[1]\n",
    "        split = 'train' if train_test_shuffle[line_no] <= train_num else 'dev'\n",
    "        #sentiment = tw_sentiment_dict[tw_id]\n",
    "        v2_words = gensim.utils.to_unicode(all_v2_words[line_no]).split('\\t')[1]\n",
    "        \n",
    "        alldocs[v1].append(SentimentDocument(stem_document(words) if stem else words, [line_no], split, sentiment))\n",
    "        alldocs[v2].append(SentimentDocument(stem_document(v2_words) if stem else v2_words, [line_no], split, sentiment))\n",
    "# test file\n",
    "with open(tw_test) as test_fh:\n",
    "    for line_no, line in enumerate(test_fh):\n",
    "        tokens = gensim.utils.to_unicode(line).split('\\t')\n",
    "        if len(tokens) != 2:\n",
    "            print line\n",
    "            raise Exception()\n",
    "        sentiment = sentiment_dict[tokens[0]]\n",
    "        #if tw_id not in tw_sentiment_dict.keys():\n",
    "        #    continue\n",
    "        words = tokens[1]\n",
    "        split = 'test'\n",
    "        \n",
    "        alldocs[v1].append(SentimentDocument(stem_document(words) if stem else words, \\\n",
    "                                             [total_num+line_no], split, sentiment))\n",
    "train_docs = {\n",
    "    v1 : [doc for doc in alldocs[v1] if doc.split == 'train'],\n",
    "    v2 : [doc for doc in alldocs[v2] if doc.split == 'train']\n",
    "}\n",
    "dev_docs = {\n",
    "    v1 : [doc for doc in alldocs[v1] if doc.split == 'dev'],\n",
    "    v2 : [doc for doc in alldocs[v2] if doc.split == 'dev']\n",
    "}\n",
    "test_docs = {\n",
    "    v1 : [doc for doc in alldocs[v1] if doc.split == 'test'],\n",
    "    v2 : [doc for doc in alldocs[v2] if doc.split == 'test']\n",
    "}\n",
    "doc_list = { v1: alldocs[v1][:], v2: alldocs[v2][:] }  # for reshuffling per pass\n",
    "\n",
    "print('%d docss: %d train, %d dev, %d test' % (len(doc_list[v1]), len(train_docs[v1]), len(dev_docs[v1]), len(test_docs[v1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view1 Doc2Vec(dm/c,d500,n5,w3,mc2,t4)\n",
      "view1 Doc2Vec(dbow,d500,n5,mc5,t4)\n",
      "view1 Doc2Vec(dm/m,d500,n5,w3,mc2,t4)\n",
      "view2 Doc2Vec(dm/c,d500,n5,w3,mc2,t4)\n",
      "view2 Doc2Vec(dbow,d500,n5,mc5,t4)\n",
      "view2 Doc2Vec(dm/m,d500,n5,w3,mc2,t4)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"this will be painfully slow otherwise\"\n",
    "model_size = 500\n",
    "simple_models , models_by_name = {}, {} \n",
    "for view in [v1, v2]:\n",
    "    simple_models[view] = [\n",
    "        # PV-DM w/concatenation - window=5 (both sides) approximates paper's 10-word total window size\n",
    "        Doc2Vec(dm=1, dm_concat=1, size=model_size, window=3, negative=5, hs=0, min_count=2, workers=cores),\n",
    "        # PV-DBOW \n",
    "        Doc2Vec(dm=0, size=model_size, negative=5, hs=0, min_count=5, workers=cores),\n",
    "        # PV-DM w/average\n",
    "        Doc2Vec(dm=1, dm_mean=1, size=model_size, window=3, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    ]\n",
    "\n",
    "    # speed setup by sharing results of 1st model's vocabulary scan\n",
    "    simple_models[view][0].build_vocab(alldocs[view])  # PV-DM/concat requires one special NULL word so it serves as template\n",
    "    print view, simple_models[view][0]\n",
    "    for model in simple_models[view][1:]:\n",
    "        model.reset_from(simple_models[view][0])\n",
    "        print view, model\n",
    "\n",
    "    models_by_name[view] = OrderedDict((str(model), model) for model in simple_models[view])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "for view in [v1, v2]:\n",
    "    models_by_name[view]['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[view][1], simple_models[view][2]])\n",
    "    models_by_name[view]['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[view][1], simple_models[view][0]])\n",
    "#print models_by_name['dbow+dmm'], models_by_name['dbow+dmc'] \n",
    "#del models_by_name['dbow+dmc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn import svm, metrics, neighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from random import sample\n",
    "\n",
    "# for timing\n",
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "import time \n",
    "import ipdb\n",
    "\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = default_timer()\n",
    "    elapser = lambda: default_timer() - start\n",
    "    yield lambda: elapser()\n",
    "    end = default_timer()\n",
    "    elapser = lambda: end-start\n",
    "    \n",
    "def logistic_predictor(train_targets, train_regressors):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train_regressors, train_targets)\n",
    "    return lr\n",
    "\n",
    "def svm_predictor(train_targets, train_regressors):\n",
    "    svc = svm.SVC(kernel='rbf', degree=5, gamma=1e-1)\n",
    "    svc.fit(train_regressors, train_targets)\n",
    "    return svc\n",
    "\n",
    "    \"\"\"expected = svm_y_test\n",
    "    predicted = svc.predict(svm_x_test)\n",
    "\n",
    "    #print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "    #      % (svc, metrics.classification_report(expected, predicted)))\n",
    "    #print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "    \"\"\"\n",
    "def rf_predictor(train_targets, train_regressors):\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "    rfc.fit(train_regressors, train_targets)\n",
    "    return rfc\n",
    "\n",
    "def error_rate_for_model(test_model, train_set, test_set, infer=False, infer_steps=3, infer_alpha=0.1, infer_subsample=0.1):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets, train_regressors = zip(*[(doc.sentiment, test_model.docvecs[doc.tags[0]]) for doc in train_set])\n",
    "    predictor = predictor_alg(train_targets, train_regressors)\n",
    "\n",
    "    test_data = test_set\n",
    "    if infer:\n",
    "        if infer_subsample < 1.0:\n",
    "            test_data = sample(test_data, int(infer_subsample * len(test_data)))\n",
    "        test_regressors = [test_model.infer_vector(doc.words, steps=infer_steps, alpha=infer_alpha) for doc in test_data]\n",
    "    else:\n",
    "        test_regressors = [test_model.docvecs[doc.tags[0]] for doc in test_data]\n",
    "    \n",
    "    # predict & evaluate\n",
    "    test_predictions = predictor.predict(test_regressors)\n",
    "    predicted = np.rint(test_predictions)\n",
    "    expected = [doc.sentiment for doc in test_data]\n",
    "    \"\"\"if not infer:\n",
    "        print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "              % (predictor, metrics.classification_report(expected, predicted)))\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\"\"\"\n",
    "    #ipdb.set_trace()\n",
    "    corrects = sum(expected == predicted)\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.linalg import eigh\n",
    "%matplotlib inline\n",
    "def center(data):\n",
    "    return data - np.mean(data, axis=0)\n",
    "\n",
    "def PLS(X, Y):\n",
    "    cross_cov = np.dot(center(X), center(Y).T)\n",
    "    eigval,eigvec=np.linalg.eig(cross_cov.dot(cross_cov.T))\n",
    "    return (eigval, eigvec)\n",
    "\n",
    "def PLS_MFCC():\n",
    "    dims = [10, 30, 50, 70, 90, 110]\n",
    "    accuracies = np.zeros((len(num_neighb), len(dims)))\n",
    "    # (score, dim, k, PLS_subspace, classifier_object)\n",
    "    best = (0, 0, 0, None, None)\n",
    "    #run pls\n",
    "    eigval, U = PLS(acoustic_train, artic_train)\n",
    "    for j, k in enumerate(num_neighb):\n",
    "        for i, d in enumerate(dims):\n",
    "            U_d = get_top_eigvec(eigval, U, d)\n",
    "            #get projection to pls space\n",
    "            train_proj = np.dot(U_d.T, acoustic_train_cen)\n",
    "            dev_proj = np.dot(U_d.T, acoustic_dev_cen)\n",
    "            # stack with mfcc39\n",
    "            stacked_train = np.append(train_proj, mfcc39_train, axis=0)\n",
    "            stacked_dev = np.append(dev_proj, mfcc39_dev, axis=0)\n",
    "\n",
    "            #classify\n",
    "            clf = neighbors.KNeighborsClassifier(k)\n",
    "            clf.fit(stacked_train.T, phones_train)\n",
    "\n",
    "            #predictions\n",
    "            score = clf.score(stacked_dev.T, phones_dev)\n",
    "            if score > best[0]:\n",
    "                best = (score, d, k, U_d, clf)\n",
    "            accuracies[j,i] = score\n",
    "    return (best, accuracies)\n",
    "\n",
    "def kcca(X, Y, regX=0.1, regY=0.1, numCC=10, kernelcca=True, ktype=\"gaussian\"):\n",
    "    '''Set up and solve the eigenproblem for the data in kernel and specified reg\n",
    "    '''\n",
    "    cenX = center(X)\n",
    "    cenY = center(Y)\n",
    "    kernel1 = np.array([_make_kernel(X.T, ktype=ktype)])\n",
    "    kernel_x = (kernel1 + kernel1.T)/2\n",
    "    kernel2 = np.array([_make_kernel(Y.T, ktype=ktype)])\n",
    "    kernel_y = (kernel2 + kernel2.T)/2\n",
    "    r_Ix = regX * np.eye(kernel_x.shape[0])\n",
    "    r_Iy = regY * np.eye(kernel_y.shape[0])\n",
    "    A = reduce(np.dot, [ np.linalg.inv(kernel_x - r_Ix), kernel_y, np.linalg.inv(kernel_y - r_Iy), kernel_x])\n",
    "    eigval,eigvec=np.linalg.eig(A)\n",
    "    return (eigval, eigvec)\n",
    "\n",
    "def _listcorr(a):\n",
    "    '''Returns pairwise row correlations for all items in array as a list of matrices\n",
    "    '''\n",
    "    corrs = np.zeros((a[0].shape[1], len(a), len(a)))\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(a)):\n",
    "            if j > i:\n",
    "                corrs[:, i, j] = [np.nan_to_num(np.corrcoef(ai, aj)[0, 1]) for (ai, aj) in zip(a[i].T, a[j].T)]\n",
    "    return corrs\n",
    "\n",
    "\n",
    "def recon(data, comp, corronly=False, kernelcca=True):\n",
    "    nT = data[0].shape[0]\n",
    "    # Get canonical variates and CCs\n",
    "    if kernelcca:\n",
    "        ws = _listdot(data, comp)\n",
    "    else:\n",
    "        ws = comp\n",
    "    ccomp = _listdot([d.T for d in data], ws)\n",
    "    corrs = _listcorr(ccomp)\n",
    "    if corronly:\n",
    "        return corrs\n",
    "    else:\n",
    "        return corrs, ws, ccomp\n",
    "\n",
    "\n",
    "def _listdot(d1, d2): return [np.dot(x[0].T, x[1]) for x in zip(d1, d2)]\n",
    "\n",
    "\n",
    "def _make_kernel(d, normalize=True, ktype=\"linear\", sigma=1.0):\n",
    "    '''Makes a kernel for data d\n",
    "      If ktype is \"linear\", the kernel is a linear inner product\n",
    "      If ktype is \"gaussian\", the kernel is a Gaussian kernel with sigma = sigma\n",
    "    '''\n",
    "    if ktype == \"linear\":\n",
    "        d = np.nan_to_num(d)\n",
    "        cd = _demean(d)\n",
    "        kernel = np.dot(cd, cd.T)\n",
    "    elif ktype == \"gaussian\":\n",
    "        from scipy.spatial.distance import pdist, squareform\n",
    "        # this is an NxD matrix, where N is number of items and D its dimensionalites\n",
    "        pairwise_dists = squareform(pdist(d, 'euclidean'))\n",
    "        kernel = np.exp(-pairwise_dists ** 2 / sigma ** 2)\n",
    "    kernel = (kernel + kernel.T) / 2.\n",
    "    kernel = kernel / np.linalg.eigvalsh(kernel).max()\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def _demean(d): return d - d.mean(0)\n",
    "\n",
    "def CCA(X, Y, regX = 0, regY = 0):\n",
    "    cenX = center(X)\n",
    "    cenY = center(Y)\n",
    "    cross_cov = cenX.dot(cenY.T)\n",
    "    covX = cenX.dot(cenX.T)\n",
    "    covY = cenY.dot(cenY.T)\n",
    "    r_Ix = regX * np.eye(covX.shape[0])\n",
    "    r_Iy = regY * np.eye(covY.shape[0])\n",
    "    A = reduce(np.dot, [ np.linalg.inv(covX + r_Ix), cross_cov, np.linalg.inv(covY + r_Iy), cross_cov.T ])\n",
    "    eigval,eigvec=np.linalg.eig(A)\n",
    "    return (eigval, eigvec)\n",
    "\n",
    "def get_top_eigvec(eigval, eigvec, k):\n",
    "    idx=np.argsort(eigval)[-k:][::-1]\n",
    "    #eigval=eigval[idx]\n",
    "    return eigvec[:,idx]\n",
    "\n",
    "def CCA_MFCC():\n",
    "    dims = [10, 30, 50, 70, 90, 110]\n",
    "    reg = [1e-8, 1e-6, 1e-4, 1e-2, 1e-1, 1e1]\n",
    "    accuracies = np.zeros((len(reg), len(reg), len(dims), len(num_neighb)))\n",
    "    # (score, dim, regX, regY, k, CCA_subspace, classifier_object)\n",
    "    best = (0, 0, 0, 0, 0, None, None)\n",
    "    for rx, regX in enumerate(reg):\n",
    "        for ry, regY in enumerate(reg):\n",
    "            #run cca\n",
    "            eigval, U = CCA(acoustic_train, artic_train, regX, regY)\n",
    "            for i, d in enumerate(dims):\n",
    "                U_d = get_top_eigvec(eigval, U, d)\n",
    "                #get projection to cca space\n",
    "                train_proj = U_d.T.dot(acoustic_train_cen)\n",
    "                dev_proj = U_d.T.dot(acoustic_dev_cen)\n",
    "                # stack with mfcc39\n",
    "                stacked_train = np.append(train_proj, mfcc39_train, axis=0)\n",
    "                stacked_dev = np.append(dev_proj, mfcc39_dev, axis=0)\n",
    "                #classify\n",
    "                for j, k in enumerate(num_neighb):\n",
    "                    clf = neighbors.KNeighborsClassifier(k)\n",
    "                    clf.fit(stacked_train.T, phones_train)\n",
    "\n",
    "                    #predictions\n",
    "                    score = clf.score(stacked_dev.T, phones_dev)\n",
    "                    if score > best[0]:\n",
    "                        best = (score, d, regX, regY, k, U_d, clf)\n",
    "                    accuracies[rx, ry, i, j] = score\n",
    "    return (best, accuracies)\n",
    "\n",
    "def plot_pc2(data, eigvec, phones_data):\n",
    "    #project to top 2 princ. comp.\n",
    "    data_proj = np.dot(np.transpose(eigvec), data)\n",
    "    data_proj_labels=[data_proj[:,np.where(phones_data==lbl)] for lbl in labels_dict.values()]\n",
    "    #Plot\n",
    "    cmap = plt.get_cmap('jet_r')\n",
    "    N=len(labels)\n",
    "    colors = [cmap(float(i)/N) for i in np.linspace(5.0, 0, N)]\n",
    "    plt.figure(figsize=(7,7))\n",
    "    #plt.subplot(2,1,1)\n",
    "    for i in range(N):\n",
    "        plt.scatter(data_proj_labels[i][0,:], data_proj_labels[i][1,:] ,c=colors[i], marker='+', label=labels[i]);\n",
    "    #plt.legend(plots,labels)\n",
    "    plt.legend(loc=3)\n",
    "    #plt.show()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from collections import defaultdict\n",
    "best_error = dd(lambda: dd(lambda :(1.0, 0.0))) # { view: { model_name : (error_rate, alpha) } } ,to selectively-print only best errors achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started.\n",
      "======== view1 =========\n",
      "START 2015-12-15 09:47:51.845102\n",
      "END 2015-12-15 09:48:32.341065\n",
      "======== view2 =========\n",
      "START 2015-12-15 09:48:32.341488\n",
      "END 2015-12-15 09:49:09.631326\n"
     ]
    }
   ],
   "source": [
    "#predictor_alg = logistic_predictor\n",
    "predictor_alg = logistic_predictor\n",
    "from random import shuffle\n",
    "import datetime\n",
    "\n",
    "print 'Started.'\n",
    "for view in [v1, v2]:\n",
    "    alpha, min_alpha, passes = (0.025, 0.001, 10)\n",
    "    alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "    print \"======== %s =========\" %view\n",
    "    print(\"START %s\" % datetime.datetime.now())\n",
    "\n",
    "    for epoch in range(passes):\n",
    "        shuffle(doc_list[view])  # shuffling gets best results\n",
    "\n",
    "        for name, train_model in models_by_name[view].items():\n",
    "            #print name\n",
    "            # train\n",
    "            duration = 'na'\n",
    "            train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "            with elapsed_timer() as elapsed:\n",
    "                train_model.train(doc_list[view])\n",
    "                duration = '%.1f' % elapsed()\n",
    "\n",
    "            # evaluate\n",
    "            eval_duration = ''\n",
    "            with elapsed_timer() as eval_elapsed:\n",
    "                err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs[view], dev_docs[view])\n",
    "            eval_duration = '%.1f' % eval_elapsed()\n",
    "            best_indicator = ' '\n",
    "            if err < best_error[view][name][0]:\n",
    "                best_error[view][name] = (err, alpha)\n",
    "                best_indicator = '*' \n",
    "            #print(\"%s%f : %i passes : %s-%s %ss %ss\" % (best_indicator, err, epoch + 1, view, name, duration, eval_duration))\n",
    "\n",
    "            \"\"\"if ((epoch + 1) % 5) == 0 or epoch == 0:\n",
    "                eval_duration = ''\n",
    "                with elapsed_timer() as eval_elapsed:\n",
    "                    infer_err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs[view], test_docs[view], infer=True)\n",
    "                eval_duration = '%.1f' % eval_elapsed()\n",
    "                best_indicator = ' '\n",
    "                if infer_err < best_error[view][name + '_inferred'][0]:\n",
    "                    best_error[view][name + '_inferred'] = (infer_err, alpha)\n",
    "                    best_indicator = '*'\n",
    "                print(\"%s%f : %i passes : %s-%s %ss %ss\" % (best_indicator, infer_err, epoch + 1, view, name + '_inferred', duration, eval_duration))\n",
    "\"\"\"\n",
    "        #print('completed pass %i at alpha %f' % (epoch + 1, alpha))\n",
    "        alpha -= alpha_delta\n",
    "\n",
    "    print(\"END %s\" % str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= view1 ========\n",
      "0.400000 dbow+dmc 0.013000\n",
      "0.411842 Doc2Vec(dm/c,d500,n5,w3,mc2,t4) 0.013000\n",
      "0.413158 dbow+dmm 0.008200\n",
      "0.422368 Doc2Vec(dbow,d500,n5,mc5,t4) 0.013000\n",
      "0.432895 Doc2Vec(dm/m,d500,n5,w3,mc2,t4) 0.008200\n",
      "========= view2 ========\n",
      "0.414474 dbow+dmc 0.017800\n",
      "0.428947 Doc2Vec(dm/c,d500,n5,w3,mc2,t4) 0.017800\n",
      "0.428947 Doc2Vec(dbow,d500,n5,mc5,t4) 0.020200\n",
      "0.443421 Doc2Vec(dm/m,d500,n5,w3,mc2,t4) 0.025000\n",
      "0.450000 dbow+dmm 0.017800\n"
     ]
    }
   ],
   "source": [
    "for view in [v1, v2]:\n",
    "    print '========= %s ========' %view\n",
    "    for rate, alpha, name in sorted((rate, alpha, name) for name, (rate, alpha) in best_error[view].items()):\n",
    "        print(\"%f %s %f\" % (rate, name, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for doc 728...\n",
      "SentimentDocument(words=u'unpack listen to the clash miss my boy', tags=[728], split='train', sentiment=-1)\n",
      "\n",
      "SentimentDocument(words=u\"i don't know what right and what real anymore. i don't know how i'm meant to feel anymore. i'v been taken over by the fear. . .\", tags=[728], split='train', sentiment=-1)\n",
      "Doc2Vec(dm/c,d500,n5,w3,mc2,t4):\n",
      " [(728, 0.7739375233650208), (3248, 0.7707007527351379), (2776, 0.7230231761932373)]\n",
      "Doc2Vec(dbow,d500,n5,mc5,t4):\n",
      " [(728, 0.8397148847579956), (3879, 0.7515110969543457), (422, 0.7322298884391785)]\n",
      "Doc2Vec(dm/m,d500,n5,w3,mc2,t4):\n",
      " [(728, 0.7690732479095459), (3606, 0.6917961239814758), (1610, 0.6907590627670288)]\n"
     ]
    }
   ],
   "source": [
    "doc_id = np.random.randint(simple_models[v2][0].docvecs.count)  # pick random doc; re-run cell for more examples\n",
    "print('for doc %d...' % doc_id)\n",
    "# Print example tweet and vector reps for both views\n",
    "print alldocs['view1'][doc_id]\n",
    "#tag = alldocs['view1'][doc_id].tags[0]\n",
    "#print '\\n', simple_models['view1'][0].docvecs[tag]\n",
    "\n",
    "print '\\n', alldocs['view2'][doc_id]\n",
    "#print '\\n', simple_models['view2'][0].docvecs[tag]\n",
    "#print '\\n\\n', doc_list['view2'][:10]\n",
    "for model in simple_models[v1]:\n",
    "    inferred_docvec = model.infer_vector(alldocs[v1][doc_id].words)\n",
    "    print('%s:\\n %s' % (model, model.docvecs.most_similar([inferred_docvec], topn=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbow+dmc\n",
      "0.013\n"
     ]
    }
   ],
   "source": [
    "#Select the best performing word2vec model\n",
    "_, best_alpha, best_model_name = min(((rate, alpha, name) \\\n",
    "                                           for name, (rate, alpha) in best_error[v1].items()), key=lambda b: b[0])\n",
    "print best_model_name \n",
    "print best_alpha\n",
    "best_model = { v1 : models_by_name[v1][best_model_name],\n",
    "              v2 : models_by_name[v2][best_model_name] }\n",
    "# Train best model\n",
    "shuffle(doc_list[view])\n",
    "for view in [v1, v2]:\n",
    "    best_model[view].alpha, best_model[view].min_alpha = best_alpha, best_alpha\n",
    "    best_model[view].train(doc_list[view])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DO CCA on the training docvecs\n",
    "# X = view 1, Y = view 2 : [word_vec_size x num_samples]\n",
    "target_sentiments, X, Y = zip(*[(doc.sentiment, best_model[v1].docvecs[doc.tags[0]], \\\n",
    "                             best_model[v2].docvecs[doc.tags[0]]) for doc in train_docs[v1]])\n",
    "X = np.asarray(X).T\n",
    "Y = np.asarray(Y).T\n",
    "#dev docs\n",
    "dev = [best_model[v1].docvecs[doc.tags[0]] for doc in dev_docs[v1]]\n",
    "dev = np.asarray(dev).T\n",
    "#test docs\n",
    "test = [best_model[v1].docvecs[doc.tags[0]] for doc in test_docs[v1]]\n",
    "test = np.asarray(test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3045) (1000, 3045)\n",
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "(cca_eigval, cca_eigvec) = CCA(X, Y)  #kcca(X, Y, regX=0.1, regY=0.1, numCC=10, kernelcca=True, ktype=\"gaussian\")\n",
    "print np.shape(X), np.shape(Y)\n",
    "print np.shape(cca_eigvec)\n",
    "#print np.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_rate(X, X_targets, test, expected, print_conf=False):\n",
    "    predictor = predictor_alg(X_targets, X)\n",
    "\n",
    "    # predict & evaluate\n",
    "    predictions = predictor.predict(test)\n",
    "    predicted = np.rint(predictions)\n",
    "    #print(\"Classification report for %s:\\n%s\\n\" % (predictor, metrics.classification_report(expected, predicted)))\n",
    "    if print_conf:\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "    #ipdb.set_trace()\n",
    "    errors = len(predictions) - sum(expected == predicted)\n",
    "    err_orig = float(errors) / len(expected)\n",
    "    if print_conf:\n",
    "        print err_orig\n",
    "    return err_orig*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[161 176]\n",
      " [139 284]]\n",
      "0.414473684211\n"
     ]
    }
   ],
   "source": [
    "expected = [doc.sentiment for doc in dev_docs[v1]]\n",
    "err_orig = error_rate(X.T, target_sentiments, dev.T, expected, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get top k eigvec, project training data and stack with original word vectors\n",
    "err_cca = []\n",
    "step = 50\n",
    "num_dir_ranges = range(step, step+model_size, step)\n",
    "for num_dir in num_dir_ranges:\n",
    "    top_k_eigv = get_top_eigvec(cca_eigval, cca_eigvec, num_dir)\n",
    "    #print np.shape(top_k_eigv)\n",
    "    X_proj = top_k_eigv.T.dot(X)\n",
    "    #print np.shape(X_proj)\n",
    "    stacked_vec = np.append(X, X_proj, axis=0)\n",
    "    #print np.shape(stacked_vec)\n",
    "\n",
    "    # project test data to cca directions and stack\n",
    "    #print np.shape(test)\n",
    "    dev_proj = top_k_eigv.T.dot(dev)\n",
    "    stacked_dev = np.append(dev, dev_proj, axis=0)\n",
    "    #print np.shape(stacked_dev)\n",
    "    #print np.shape(target_sentiments)\n",
    "    \n",
    "    expected = [doc.sentiment for doc in dev_docs[v1]]\n",
    "    err_cca.append(error_rate(stacked_vec.T, target_sentiments, stacked_dev.T, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEPCAYAAABhkeIdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1110e8250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_dir_ranges, [err_orig]*len(num_dir_ranges), 'r--', num_dir_ranges, err_cca, 'b*')\n",
    "plt.ylabel('Mis-classification rate')\n",
    "plt.xlabel('Number of CCA directions stacked with original sentence vectors')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 71 106]\n",
      " [ 47 135]]\n",
      "0.426183844011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42.618384401114206"
      ]
     },
     "execution_count": 1493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test - doc2vec\n",
    "expected = [doc.sentiment for doc in test_docs[v1]]\n",
    "error_rate(X.T, target_sentiments, test.T, expected, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 71 106]\n",
      " [ 47 135]]\n",
      "0.426183844011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42.618384401114206"
      ]
     },
     "execution_count": 1494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test doc2vec stacked with cca\n",
    "top_k_eigv = get_top_eigvec(cca_eigval, cca_eigvec, 400)\n",
    "#print np.shape(top_k_eigv)\n",
    "X_proj = top_k_eigv.T.dot(X)\n",
    "#print np.shape(X_proj)\n",
    "stacked_vec = np.append(X, X_proj, axis=0)\n",
    "#print np.shape(stacked_vec)\n",
    "\n",
    "# project test data to cca directions and stack\n",
    "#print np.shape(test)\n",
    "test_proj = top_k_eigv.T.dot(test)\n",
    "stacked_test = np.append(test, test_proj, axis=0)\n",
    "#print np.shape(stacked_test)\n",
    "#print np.shape(target_sentiments)\n",
    "\n",
    "expected = [doc.sentiment for doc in test_docs[v1]]\n",
    "error_rate(stacked_vec.T, target_sentiments, stacked_test.T, expected, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1495,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "corpus = [doc.words for doc in alldocs[v1]]\n",
    "tf_idf = vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(tf_idf)\n",
    "tf_X = tf_idf[np.array([doc.tags[0] for doc in train_docs[v1]])]\n",
    "tf_dev = tf_idf[np.array([doc.tags[0] for doc in dev_docs[v1]])]\n",
    "tf_test = tf_idf[np.array([doc.tags[0] for doc in test_docs[v1]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[197 140]\n",
      " [ 92 331]]\n",
      "0.305263157895\n"
     ]
    }
   ],
   "source": [
    "expected = [doc.sentiment for doc in dev_docs[v1]]\n",
    "#TF-IDF\n",
    "err_tf = error_rate(tf_X, target_sentiments, \\\n",
    "           tf_dev, expected, True)\n",
    "#Tf-IDF stacked with CCA\n",
    "err_tf_cca = []\n",
    "step = 50\n",
    "num_dir_ranges = range(step, step+model_size, step)\n",
    "for num_dir in num_dir_ranges:\n",
    "    top_k_eigv = get_top_eigvec(cca_eigval, cca_eigvec, num_dir)\n",
    "    #print np.shape(top_k_eigv)\n",
    "    X_proj = top_k_eigv.T.dot(X)\n",
    "    #print np.shape(X_proj)\n",
    "    stacked_vec = np.append(X, X_proj, axis=0)\n",
    "    #print np.shape(stacked_vec)\n",
    "\n",
    "    # project test data to cca directions and stack\n",
    "    #print np.shape(test)\n",
    "    dev_proj = top_k_eigv.T.dot(dev)\n",
    "    stacked_dev = np.append(dev, dev_proj, axis=0)\n",
    "    #print np.shape(stacked_dev)\n",
    "    #print np.shape(target_sentiments)\n",
    "    err_tf_cca.append(error_rate(np.append(tf_X, X_proj.T, axis=1), target_sentiments, \\\n",
    "               np.append(tf_dev, dev_proj.T, axis=1), expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[205 132]\n",
      " [107 316]]\n",
      "0.314473684211\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF stacked with doc2vec\n",
    "err_tf_doc = error_rate(np.append(tf_X, X.T, axis=1), target_sentiments, \\\n",
    "               np.append(tf_dev, dev.T, axis=1), expected, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEPCAYAAABsj5JaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110e944d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_dir_ranges, [err_tf]*len(num_dir_ranges), 'r--', num_dir_ranges, \\\n",
    "         [err_tf_doc]*len(num_dir_ranges), 'g--', num_dir_ranges, err_tf_cca, 'b*')\n",
    "plt.ylabel('Mis-classification rate')\n",
    "plt.xlabel('Number of CCA directions stacked with TF-IDF vectors')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Doc2Vec generally does better With Stemming, and gives the best accuracy on test when stacked with tf-idf\n",
    "# Stacking tf-idf with cca usually does marginally worse, but seemingly better than tf-idf+doc2vec when not stemmed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
