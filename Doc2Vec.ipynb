{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data/view1_clean not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#Split the all_views, get one file(sentiment, tweet) for each view\n",
    "#Clean each view\n",
    "#Run this for each view.\n",
    "norm() {\n",
    "    fn=$1\n",
    "    if [ ! -f \"$fn\" ]\n",
    "    then\n",
    "        echo \"File: $fn not found\"\n",
    "        exit\n",
    "    fi\n",
    "    #this function will convert text to lowercase and will disconnect punctuation and special symbols from words\n",
    "    function normalize_text {\n",
    "        awk '{print tolower($0);}' < $1 | sed -e 's/\\./ \\. /g' -e 's/<br \\/>/ /g' -e 's/\"/ \" /g' \\\n",
    "        -e 's/,/ , /g' -e 's/(/ ( /g' -e 's/)/ ) /g' -e 's/\\!/ \\! /g' -e 's/\\?/ \\? /g' \\\n",
    "        -e 's/\\;/ \\; /g' -e 's/\\:/ \\: /g' > $1-norm\n",
    "    }\n",
    "    export LC_ALL=C\n",
    "    normalize_text \"$fn\"\n",
    "    wc -l $fn\n",
    "    mv \"$fn\" \"$fn-norm\"\n",
    "}\n",
    "norm \"data/view1_clean\" #file name is\n",
    "norm \"data/view2_clean\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "tw_view_1 = 'data/view1_clean-norm'\n",
    "tw_view_2 = 'data/view2_clean-norm'\n",
    "assert os.path.isfile(tw_view_1), tw_view_1 + \" unavailable\"\n",
    "assert os.path.isfile(tw_view_2), tw_view_2 + \" unavailable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3805 docs: 2664 train-sentiment, 1141 test-sentiment\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple, defaultdict as dd\n",
    "\n",
    "#sentiment = {'positive':1, 'negative':-1} #, 'neutral':2}\n",
    "sentiment_dict = {'4':1, '0':-1} #- new data 0,4\n",
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags split sentiment')\n",
    "\n",
    "alldocs = dd(list)  # will hold all docs in original order - dictionary, keys = [v1, v2]\n",
    "v1 = 'view1'\n",
    "v2 = 'view2'\n",
    "#tw_sentiment_dict = {}\n",
    "#print total_num, train_test_shuffle\n",
    "all_v2_words = []\n",
    "with open(tw_view_2) as allview2:\n",
    "        all_v2_words = allview2.readlines()\n",
    "total_num = len(all_v2_words)\n",
    "#split train/test\n",
    "train_num = total_num *  7 / 10 # 70% train/test 1 - 10\n",
    "train_test_shuffle = np.arange(total_num)\n",
    "np.random.shuffle(train_test_shuffle)\n",
    "with open(tw_view_1) as allview1:\n",
    "    #for line_no, (v1, v2) in enumerate(zip(allview1, allview2)):\n",
    "    for line_no, line in enumerate(allview1):\n",
    "        tokens = gensim.utils.to_unicode(line).split('\\t')\n",
    "        if len(tokens) != 2:\n",
    "            print line\n",
    "            raise Exception()\n",
    "        sentiment = sentiment_dict[tokens[0]]\n",
    "        #if tw_id not in tw_sentiment_dict.keys():\n",
    "        #    continue\n",
    "        words = tokens[1]\n",
    "        split = 'train' if train_test_shuffle[line_no] <= train_num else 'test'\n",
    "        #sentiment = tw_sentiment_dict[tw_id]\n",
    "        v2_words = gensim.utils.to_unicode(all_v2_words[line_no]).split('\\t')[1]\n",
    "        \n",
    "        alldocs[v1].append(SentimentDocument(words, [line_no], split, sentiment))\n",
    "        alldocs[v2].append(SentimentDocument(v2_words, [line_no], split, sentiment))\n",
    "train_docs = {\n",
    "    v1 : [doc for doc in alldocs[v1] if doc.split == 'train'],\n",
    "    v2 : [doc for doc in alldocs[v2] if doc.split == 'train']\n",
    "}\n",
    "test_docs = {\n",
    "    v1 : [doc for doc in alldocs[v1] if doc.split == 'test'],\n",
    "    v2 : [doc for doc in alldocs[v2] if doc.split == 'test']\n",
    "}\n",
    "doc_list = { v1: alldocs[v1][:], v2: alldocs[v2][:] }  # for reshuffling per pass\n",
    "\n",
    "print('%d docs: %d train-sentiment, %d test-sentiment' % (len(doc_list[v1]), len(train_docs[v1]), len(test_docs[v1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view1 Doc2Vec(dm/c,d200,n5,w3,mc2,t4)\n",
      "view1 Doc2Vec(dbow,d200,n5,mc5,t4)\n",
      "view1 Doc2Vec(dm/m,d200,n5,w3,mc2,t4)\n",
      "view2 Doc2Vec(dm/c,d200,n5,w3,mc2,t4)\n",
      "view2 Doc2Vec(dbow,d200,n5,mc5,t4)\n",
      "view2 Doc2Vec(dm/m,d200,n5,w3,mc2,t4)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"this will be painfully slow otherwise\"\n",
    "model_size = 200\n",
    "simple_models , models_by_name = {}, {} \n",
    "for view in [v1, v2]:\n",
    "    simple_models[view] = [\n",
    "        # PV-DM w/concatenation - window=5 (both sides) approximates paper's 10-word total window size\n",
    "        Doc2Vec(dm=1, dm_concat=1, size=model_size, window=3, negative=5, hs=0, min_count=2, workers=cores),\n",
    "        # PV-DBOW \n",
    "        Doc2Vec(dm=0, size=model_size, negative=5, hs=0, min_count=5, workers=cores),\n",
    "        # PV-DM w/average\n",
    "        Doc2Vec(dm=1, dm_mean=1, size=model_size, window=3, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    ]\n",
    "\n",
    "    # speed setup by sharing results of 1st model's vocabulary scan\n",
    "    simple_models[view][0].build_vocab(alldocs[view])  # PV-DM/concat requires one special NULL word so it serves as template\n",
    "    print view, simple_models[view][0]\n",
    "    for model in simple_models[view][1:]:\n",
    "        model.reset_from(simple_models[view][0])\n",
    "        print view, model\n",
    "\n",
    "    models_by_name[view] = OrderedDict((str(model), model) for model in simple_models[view])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "for view in [v1, v2]:\n",
    "    models_by_name[view]['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[view][1], simple_models[view][2]])\n",
    "    models_by_name[view]['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[view][1], simple_models[view][0]])\n",
    "#print models_by_name['dbow+dmm'], models_by_name['dbow+dmc'] \n",
    "#del models_by_name['dbow+dmc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn import svm, metrics, neighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from random import sample\n",
    "\n",
    "# for timing\n",
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "import time \n",
    "import ipdb\n",
    "\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = default_timer()\n",
    "    elapser = lambda: default_timer() - start\n",
    "    yield lambda: elapser()\n",
    "    end = default_timer()\n",
    "    elapser = lambda: end-start\n",
    "    \n",
    "def logistic_predictor(train_targets, train_regressors):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train_regressors, train_targets)\n",
    "    return lr\n",
    "\n",
    "def svm_predictor(train_targets, train_regressors):\n",
    "    svc = svm.SVC(kernel='rbf', degree=5, gamma=1e-1)\n",
    "    svc.fit(train_regressors, train_targets)\n",
    "    return svc\n",
    "\n",
    "    \"\"\"expected = svm_y_test\n",
    "    predicted = svc.predict(svm_x_test)\n",
    "\n",
    "    #print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "    #      % (svc, metrics.classification_report(expected, predicted)))\n",
    "    #print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "    \"\"\"\n",
    "def rf_predictor(train_targets, train_regressors):\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "    rfc.fit(train_regressors, train_targets)\n",
    "    return rfc\n",
    "\n",
    "def error_rate_for_model(test_model, train_set, test_set, infer=False, infer_steps=3, infer_alpha=0.1, infer_subsample=0.1):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets, train_regressors = zip(*[(doc.sentiment, test_model.docvecs[doc.tags[0]]) for doc in train_set])\n",
    "    #train_regressors = sm.add_constant(train_regressors)\n",
    "    predictor = logistic_predictor(train_targets, train_regressors)\n",
    "    #predictor = svm_predictor(train_targets, train_regressors)\n",
    "\n",
    "    test_data = test_set\n",
    "    if infer:\n",
    "        if infer_subsample < 1.0:\n",
    "            test_data = sample(test_data, int(infer_subsample * len(test_data)))\n",
    "        test_regressors = [test_model.infer_vector(doc.words, steps=infer_steps, alpha=infer_alpha) for doc in test_data]\n",
    "    else:\n",
    "        test_regressors = [test_model.docvecs[doc.tags[0]] for doc in test_data]\n",
    "    #test_regressors = sm.add_constant(test_regressors)\n",
    "    \n",
    "    # predict & evaluate\n",
    "    test_predictions = predictor.predict(test_regressors)\n",
    "    predicted = np.rint(test_predictions)\n",
    "    expected = [doc.sentiment for doc in test_data]\n",
    "    \"\"\"if not infer:\n",
    "        print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "              % (predictor, metrics.classification_report(expected, predicted)))\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\"\"\"\n",
    "    #ipdb.set_trace()\n",
    "    corrects = sum(expected == predicted)\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "def center(data):\n",
    "    return data - np.mean(data, axis=0)\n",
    "\n",
    "def PLS(X, Y):\n",
    "    cross_cov = np.dot(center(X), center(Y).T)\n",
    "    eigval,eigvec=np.linalg.eig(cross_cov.dot(cross_cov.T))\n",
    "    return (eigval, eigvec)\n",
    "\n",
    "def PLS_MFCC():\n",
    "    dims = [10, 30, 50, 70, 90, 110]\n",
    "    accuracies = np.zeros((len(num_neighb), len(dims)))\n",
    "    # (score, dim, k, PLS_subspace, classifier_object)\n",
    "    best = (0, 0, 0, None, None) \n",
    "    #run pls\n",
    "    eigval, U = PLS(acoustic_train, artic_train)\n",
    "    for j, k in enumerate(num_neighb):\n",
    "        for i, d in enumerate(dims):\n",
    "            U_d = get_top_eigvec(eigval, U, d)\n",
    "            #get projection to pls space\n",
    "            train_proj = np.dot(U_d.T, acoustic_train_cen)\n",
    "            dev_proj = np.dot(U_d.T, acoustic_dev_cen)\n",
    "            # stack with mfcc39\n",
    "            stacked_train = np.append(train_proj, mfcc39_train, axis=0)\n",
    "            stacked_dev = np.append(dev_proj, mfcc39_dev, axis=0)\n",
    "            \n",
    "            #classify\n",
    "            clf = neighbors.KNeighborsClassifier(k)\n",
    "            clf.fit(stacked_train.T, phones_train)\n",
    "\n",
    "            #predictions\n",
    "            score = clf.score(stacked_dev.T, phones_dev)\n",
    "            if score > best[0]:\n",
    "                best = (score, d, k, U_d, clf)\n",
    "            accuracies[j,i] = score\n",
    "    return (best, accuracies)\n",
    "\n",
    "def CCA(X, Y, regX = 0, regY = 0):\n",
    "    cenX = center(X)\n",
    "    cenY = center(Y)\n",
    "    cross_cov = cenX.dot(cenY.T)\n",
    "    covX = cenX.dot(cenX.T)\n",
    "    covY = cenY.dot(cenY.T)\n",
    "    r_Ix = regX * np.eye(covX.shape[0])\n",
    "    r_Iy = regY * np.eye(covY.shape[0])\n",
    "    A = reduce(np.dot, [ np.linalg.inv(covX + r_Ix), cross_cov, np.linalg.inv(covY + r_Iy), cross_cov.T ])\n",
    "    eigval,eigvec=np.linalg.eig(A)\n",
    "    return (eigval, eigvec)\n",
    "\n",
    "def get_top_eigvec(eigval, eigvec, k):\n",
    "    idx=np.argsort(eigval)[-k:][::-1]\n",
    "    #eigval=eigval[idx]\n",
    "    return eigvec[:,idx]\n",
    "\n",
    "def CCA_MFCC():\n",
    "    dims = [10, 30, 50, 70, 90, 110]\n",
    "    reg = [1e-8, 1e-6, 1e-4, 1e-2, 1e-1, 1e1]\n",
    "    accuracies = np.zeros((len(reg), len(reg), len(dims), len(num_neighb)))\n",
    "    # (score, dim, regX, regY, k, CCA_subspace, classifier_object)\n",
    "    best = (0, 0, 0, 0, 0, None, None)\n",
    "    for rx, regX in enumerate(reg):\n",
    "        for ry, regY in enumerate(reg):              \n",
    "            #run cca\n",
    "            eigval, U = CCA(acoustic_train, artic_train, regX, regY)\n",
    "            for i, d in enumerate(dims):\n",
    "                U_d = get_top_eigvec(eigval, U, d)\n",
    "                #get projection to cca space\n",
    "                train_proj = U_d.T.dot(acoustic_train_cen)\n",
    "                dev_proj = U_d.T.dot(acoustic_dev_cen)\n",
    "                # stack with mfcc39\n",
    "                stacked_train = np.append(train_proj, mfcc39_train, axis=0)\n",
    "                stacked_dev = np.append(dev_proj, mfcc39_dev, axis=0)\n",
    "                #classify\n",
    "                for j, k in enumerate(num_neighb):\n",
    "                    clf = neighbors.KNeighborsClassifier(k)\n",
    "                    clf.fit(stacked_train.T, phones_train)\n",
    "\n",
    "                    #predictions\n",
    "                    score = clf.score(stacked_dev.T, phones_dev)\n",
    "                    if score > best[0]:\n",
    "                        best = (score, d, regX, regY, k, U_d, clf)\n",
    "                    accuracies[rx, ry, i, j] = score\n",
    "    return (best, accuracies)\n",
    "\n",
    "def plot_pc2(data, eigvec, phones_data):\n",
    "    #project to top 2 princ. comp.\n",
    "    data_proj = np.dot(np.transpose(eigvec), data)\n",
    "    data_proj_labels=[data_proj[:,np.where(phones_data==lbl)] for lbl in labels_dict.values()]\n",
    "    #Plot\n",
    "    cmap = plt.get_cmap('jet_r')\n",
    "    N=len(labels)\n",
    "    colors = [cmap(float(i)/N) for i in np.linspace(5.0, 0, N)]\n",
    "    plt.figure(figsize=(7,7))\n",
    "    #plt.subplot(2,1,1)\n",
    "    for i in range(N):\n",
    "        plt.scatter(data_proj_labels[i][0,:], data_proj_labels[i][1,:] ,c=colors[i], marker='+', label=labels[i]);\n",
    "    #plt.legend(plots,labels)\n",
    "    plt.legend(loc=3)\n",
    "    #plt.show()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from collections import defaultdict\n",
    "best_error = dd(lambda: dd(lambda :(1.0, 0.0))) # { view: { model_name : (error_rate, alpha) } } ,to selectively-print only best errors achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started.\n",
      "======== view1 =========\n",
      "START 2015-12-11 11:06:33.716245\n",
      "END 2015-12-11 11:06:53.310037\n",
      "======== view2 =========\n",
      "START 2015-12-11 11:06:53.310469\n",
      "END 2015-12-11 11:07:10.131384\n"
     ]
    }
   ],
   "source": [
    "print 'Started.'\n",
    "from random import shuffle\n",
    "import datetime\n",
    "\n",
    "for view in [v1, v2]:\n",
    "    alpha, min_alpha, passes = (0.025, 0.001, 10)\n",
    "    alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "    print \"======== %s =========\" %view\n",
    "    print(\"START %s\" % datetime.datetime.now())\n",
    "\n",
    "    for epoch in range(passes):\n",
    "        shuffle(doc_list[view])  # shuffling gets best results\n",
    "\n",
    "        for name, train_model in models_by_name[view].items():\n",
    "            #print name\n",
    "            # train\n",
    "            duration = 'na'\n",
    "            train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "            with elapsed_timer() as elapsed:\n",
    "                train_model.train(doc_list[view])\n",
    "                duration = '%.1f' % elapsed()\n",
    "\n",
    "            # evaluate\n",
    "            eval_duration = ''\n",
    "            with elapsed_timer() as eval_elapsed:\n",
    "                err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs[view], test_docs[view])\n",
    "            eval_duration = '%.1f' % eval_elapsed()\n",
    "            best_indicator = ' '\n",
    "            if err < best_error[view][name][0]:\n",
    "                best_error[view][name] = (err, alpha)\n",
    "                best_indicator = '*' \n",
    "            #print(\"%s%f : %i passes : %s-%s %ss %ss\" % (best_indicator, err, epoch + 1, view, name, duration, eval_duration))\n",
    "\n",
    "            \"\"\"if ((epoch + 1) % 5) == 0 or epoch == 0:\n",
    "                eval_duration = ''\n",
    "                with elapsed_timer() as eval_elapsed:\n",
    "                    infer_err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs[view], test_docs[view], infer=True)\n",
    "                eval_duration = '%.1f' % eval_elapsed()\n",
    "                best_indicator = ' '\n",
    "                if infer_err < best_error[view][name + '_inferred'][0]:\n",
    "                    best_error[view][name + '_inferred'] = (infer_err, alpha)\n",
    "                    best_indicator = '*'\n",
    "                print(\"%s%f : %i passes : %s-%s %ss %ss\" % (best_indicator, infer_err, epoch + 1, view, name + '_inferred', duration, eval_duration))\n",
    "\"\"\"\n",
    "        #print('completed pass %i at alpha %f' % (epoch + 1, alpha))\n",
    "        alpha -= alpha_delta\n",
    "\n",
    "    print(\"END %s\" % str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= view1 ========\n",
      "0.368098 dbow+dmm 0.008200\n",
      "0.371604 Doc2Vec(dbow,d200,n5,mc5,t4) 0.005800\n",
      "0.371604 dbow+dmc 0.008200\n",
      "0.414549 Doc2Vec(dm/m,d200,n5,w3,mc2,t4) 0.015400\n",
      "0.428571 Doc2Vec(dm/c,d200,n5,w3,mc2,t4) 0.013000\n",
      "========= view2 ========\n",
      "0.453111 dbow+dmm 0.025000\n",
      "0.455741 Doc2Vec(dm/m,d200,n5,w3,mc2,t4) 0.008200\n",
      "0.458370 Doc2Vec(dm/c,d200,n5,w3,mc2,t4) 0.015400\n",
      "0.458370 dbow+dmc 0.022600\n",
      "0.460123 Doc2Vec(dbow,d200,n5,mc5,t4) 0.005800\n"
     ]
    }
   ],
   "source": [
    "for view in [v1, v2]:\n",
    "    print '========= %s ========' %view\n",
    "    for rate, alpha, name in sorted((rate, alpha, name) for name, (rate, alpha) in best_error[view].items()):\n",
    "        print(\"%f %s %f\" % (rate, name, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentDocument(words=u'successful night @ Tikis\\n', tags=[700], split='train', sentiment=1)\n",
      "\n",
      "SentimentDocument(words=u'Pink Tiki TONIGHT @ Tikis Grill & Bar in Waikiki Beach Hotel, 21 and over. 3 hours FREE Valet Parking, $3 Drink Specials, Come visit us ||Positive||\\n', tags=[700], split='train', sentiment=1)\n"
     ]
    }
   ],
   "source": [
    "# Print some example tweets and their vector reps for both views\n",
    "index = 700\n",
    "print alldocs['view1'][index]\n",
    "tag = alldocs['view1'][index].tags[0]\n",
    "#print '\\n', simple_models['view1'][0].docvecs[tag]\n",
    "\n",
    "print '\\n', alldocs['view2'][index]\n",
    "#print '\\n', simple_models['view2'][0].docvecs[tag]\n",
    "#print '\\n\\n', doc_list['view2'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for doc 1229...\n",
      "Doc2Vec(dm/c,d200,n5,w3,mc2,t4):\n",
      " [(1229, 0.8255937099456787), (2014, 0.7251479625701904), (2492, 0.7069324254989624)]\n",
      "Doc2Vec(dbow,d200,n5,mc5,t4):\n",
      " [(1229, 0.8826407790184021), (3217, 0.7176773548126221), (1867, 0.7105494737625122)]\n",
      "Doc2Vec(dm/m,d200,n5,w3,mc2,t4):\n",
      " [(1229, 0.8244785666465759), (360, 0.7216477394104004), (2013, 0.7074535489082336)]\n"
     ]
    }
   ],
   "source": [
    "doc_id = np.random.randint(simple_models[v1][0].docvecs.count)  # pick random doc; re-run cell for more examples\n",
    "print('for doc %d...' % doc_id)\n",
    "for model in simple_models[v1]:\n",
    "    inferred_docvec = model.infer_vector(alldocs[v1][doc_id].words)\n",
    "    print('%s:\\n %s' % (model, model.docvecs.most_similar([inferred_docvec], topn=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbow+dmm\n",
      "0.0082\n"
     ]
    }
   ],
   "source": [
    "#Select the best performing word2vec model\n",
    "_, best_alpha, best_model_name = min(((rate, alpha, name) \\\n",
    "                                           for name, (rate, alpha) in best_error[v1].items()), key=lambda b: b[0])\n",
    "print best_model_name \n",
    "print best_alpha\n",
    "best_model = { v1 : models_by_name[v1][best_model_name],\n",
    "              v2 : models_by_name[v2][best_model_name] }\n",
    "# Train best model\n",
    "shuffle(doc_list[view])\n",
    "for view in [v1, v2]:\n",
    "    best_model[v1].alpha, best_model[v1].min_alpha = best_alpha, best_alpha\n",
    "    best_model[v1].train(doc_list[view])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # DO CCA on the training docvecs\n",
    "# X = view 1, Y = view 2 : [num_samples x word_vec_size]\n",
    "target_sentiments, X, Y = zip(*[(doc.sentiment, best_model[v1].docvecs[doc.tags[0]], \\\n",
    "                             best_model[v2].docvecs[doc.tags[0]]) for doc in train_docs[v1]])\n",
    "X = np.asarray(X).T\n",
    "Y = np.asarray(Y).T\n",
    "#test docs\n",
    "test = [best_model[v1].docvecs[doc.tags[0]] for doc in test_docs[v1]]\n",
    "test = np.asarray(test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2664) (400, 2664)\n"
     ]
    }
   ],
   "source": [
    "(cca_eigval, cca_eigvec) = CCA(X, Y)\n",
    "print np.shape(X), np.shape(Y)\n",
    "#print np.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[276 253]\n",
      " [170 442]]\n",
      "0.370727432077\n"
     ]
    }
   ],
   "source": [
    "predictor = logistic_predictor(target_sentiments, X.T)\n",
    "\n",
    "# predict & evaluate\n",
    "test_predictions = predictor.predict(test.T)\n",
    "predicted = np.rint(test_predictions)\n",
    "expected = [doc.sentiment for doc in test_docs[v1]]\n",
    "#print(\"Classification report for %s:\\n%s\\n\" % (predictor, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "#ipdb.set_trace()\n",
    "errors = len(test_predictions) - sum(expected == predicted)\n",
    "err_orig = float(errors) / len(expected)\n",
    "print err_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get top k eigvec, project training data and stack with original word vectors\n",
    "err_cca = []\n",
    "step = 5\n",
    "num_dir_ranges = range(step, step+200, step)\n",
    "for num_dir in num_dir_ranges:\n",
    "    top_k_eigv = get_top_eigvec(cca_eigval, cca_eigvec, num_dir)\n",
    "    #print np.shape(top_k_eigv)\n",
    "    X_proj = top_k_eigv.T.dot(X)\n",
    "    #print np.shape(X_proj)\n",
    "    stacked_vec = np.append(X, X_proj, axis=0)\n",
    "    #print np.shape(stacked_vec)\n",
    "\n",
    "    # project test data to cca directions and stack\n",
    "    #print np.shape(test)\n",
    "    test_proj = top_k_eigv.T.dot(test)\n",
    "    stacked_test = np.append(test, test_proj, axis=0)\n",
    "    #print np.shape(stacked_test)\n",
    "    #print np.shape(target_sentiments)\n",
    "\n",
    "    predictor = logistic_predictor(target_sentiments, stacked_vec.T)\n",
    "\n",
    "    # predict & evaluate\n",
    "    test_predictions = predictor.predict(stacked_test.T)\n",
    "    predicted = np.rint(test_predictions)\n",
    "    expected = [doc.sentiment for doc in test_docs[v1]]\n",
    "    #print(\"Classification report for %s:\\n%s\\n\" % (predictor, metrics.classification_report(expected, predicted)))\n",
    "    #print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "    #ipdb.set_trace()\n",
    "    errors = len(test_predictions) - sum(expected == predicted)\n",
    "    err_cca.append(float(errors) / len(expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEPCAYAAAB2s3LUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS7jAMTOzlnCBY2ZmLfH/Aej9Ei8rVah1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111161510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(num_dir_ranges, [err_orig]*len(num_dir_ranges), 'r--', num_dir_ranges, err_cca, 'b*')\n",
    "plt.ylabel('Mis-classification rate')\n",
    "plt.xlabel('Number of CCA directions stacked with original sentence vectors')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
